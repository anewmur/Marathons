\section{Модель с поправкой по возрасту}

\textit{
В предыдущих главах мы построили два базовых уровня модели для логарифма времени финиша $Y=\ln T$. На первом уровне для каждого пола $g$ задавался общий базовый показатель без учёта различий трасс и возраста. На втором уровне различия трасс учитывались через переход на нормированную логарифмическую шкалу $Z=\ln T-\ln R_{c,g,-j}$, где $R_{c,g,-j}$ --- это эталон трассы  $c$, $g$ — пол, $j$ — целевой год. Индекс «$-j$» в обозначении эталона означает, что при его построении год $j$ исключается. Это так называемый режим leave-one-year-out (LOY), который необходим для честной проверки модели: мы тестируем предсказания на данных, которые не участвовали в построении эталона. В этой главе мы обобщаем принцип нормировки и вводим общее обозначение $\hat R^{\text{use}}_{c,g}(j)$ для эталона, используемого в конкретной ситуации. В режиме LOY это будет $\hat R^{\text{use}}_{c,g}(j)=\hat R_{c,g,-j}$, то есть эталон без года $j$. В рабочем режиме (production) $\hat R^{\text{use}}_{c,g}(j)$ строится по всем доступным данным, включая год $j$, если он есть. Разница между режимами принципиальна: LOY нужен для проверки качества модели на исторических данных, а рабочий режим — для реальных прогнозов, где мы используем всю имеющуюся информацию. Далее мы вводим возрастную поправку $h_g(a)$ как отдельный компонент регрессионной модели на нормированной шкале. Эта функция возраста $a$ корректирует прогноз в зависимости от возраста бегуна и применяется в обоих режимах. Неопределённость индивидуальной случайной компоненты и неопределённость самого эталона учитываются методом Монте-Карло, что позволяет делать прогноз для условий $(c^\ast, g^\ast, j^\ast, a_{\text{new}})$, где $c^\ast$ — целевая трасса, $g^\ast$ — пол, $j^\ast$ — год прогноза, и $a_{\text{new}}$ — возраст бегуна.}

\subsection{Постановка задачи}

Эта глава добавляет к нормировке на сложность трассы явную поправку по возрасту.
Как и раньше, работаем с логарифмом времени финиша $Y=\ln T$ и вычитаем эталон трассы, чтобы перейти на нормированную шкалу.

Пусть индекс $r$ нумерует наблюдения.
Каждому $r$ соответствует один выбранный старт участника и набор индексов $(i_r,j_r,c_r,g_r)$, возраст $a_r$ и время финиша $T_r>0$.

Для нормировки требуется эталон, который используется в конкретной ситуации при целевом годе $j$.
Его оценку обозначаем $\hat R^{\textup{use}}_{c,g}(j)$.
Это общее обозначение, а конкретное правило выбора задаётся режимом построения:
в режиме LOY (leave-one-year-out) для исторического года $j$ берём
$$
\hat R^{\textup{use}}_{c,g}(j)=\hat R_{c,g,-j},
$$
то есть эталон, построенный без данных года $j$;
в рабочем режиме (production) $\hat R^{\textup{use}}_{c,g}(j)$ строится по всем доступным данным (включая год $j$, если он есть).

Наблюдаемое нормированное значение для старта $r$ определим как
$$
z_r=\ln T_r-\ln \hat R^{\textup{use}}_{c_r,g_r}(j_r).
$$
Совокупность $\{z_r\}$ рассматривается как входные данные настоящей модели.
Мы трактуем $\{z_r\}$ как мультимножество: одинаковые значения $z$ могут встречаться несколько раз,
и каждое наблюдение учитывается отдельно.

Обозначим через $J$ множество календарных годов, которые встречаются в данных хотя бы в одной паре $(c,g)$.
При этом принадлежность $j\in J$ не гарантирует, что эталон доступен для конкретной пары $(c,g)$:
доступность всегда проверяется локально по размеру выборки для выбранного набора годов, фактически используемых при построении эталона.

Задача главы состоит из двух частей.
Во-первых, для каждого пола $g$ оценить возрастную функцию $h_g(a)$ по наблюдаемым значениям $z_r$.
Во-вторых, для условий цели $(c^\ast,g^\ast,j^\ast,a_{\textup{new}})$ описать прогнозное распределение случайной величины
$Z_{\textup{new}}$ на нормированной шкале $Z$ в точке $a_{\textup{new}}$.

После этого, используя выбранный эталон $\hat R^{\textup{use}}$ и добавку $\delta$, описывающую неопределённость эталона на шкале $Y=\ln T$, получаем
$$
Y=\ln \hat R^{\textup{use}}+Z_{\textup{new}}+\delta,
\qquad
T=\exp(Y).
$$
Совместный учёт $Z_{\textup{new}}$ и $\delta$ выполняется моделированием методом Монте-Карло; детали протоколов выбора $(\hat R^{\textup{use}},\tau^{2,\textup{use}})$ и построения $\delta$ описаны далее.


\subsection{Модель на шкале $Z$}

На нормированной шкале
$$
Z=\ln T-\ln R^{\textup{use}}_{c,g}(j)
$$
используем простую регрессионную модель, одинаковую по форме для всех режимов построения эталона.
Случайная величина на этой шкале обозначается $Z_{i,j,c,g}$ и задаётся уравнениями
\begin{equation}
Z_{i,j,c,g}=m_{i,j,c,g}+\varepsilon_{i,j,c,g},
\qquad
\varepsilon_{i,j,c,g}\sim N(0,\sigma_g^2),
\label{eq:age_model_Z}
\end{equation}
\begin{equation}
m_{i,j,c,g}=\mu_g+\gamma_g x_{i,j,c,g}+h_g\!\bigl(a_{i,j,c,g}\bigr).
\label{eq:age_model_mean}
\end{equation}
Здесь $\varepsilon_{i,j,c,g}$ — случайная ошибка (остаток) на нормированной шкале $Z$.
Она собирает всё, что не объясняется средним уровнем $\mu_g$, линейным трендом $\gamma_g x$ и возрастной функцией $h_g(a)$: индивидуальные отклонения конкретного участника от «среднего» профиля своего пола и возраста, а также прочие неконтролируемые факторы.
На уровне этой главы $\varepsilon$ трактуется как индивидуальный разброс вокруг возрастной кривой при фиксированной нормировке по эталону.

 В следующих главах эта случайная часть будет уточняться: её можно будет раскладывать на более содержательные компоненты (например, добавляя отдельные случайные поправки для участника, трассы, года или других факторов) и оценивать их параметры совместно с остальными, уменьшая долю необъяснённого разброса, которая остаётся в «остатке».

Стандартизованный возраст задаётся как
$$
x_{i,j,c,g}=\frac{a_{i,j,c,g}-a^o}{A},
$$
где константы $a^o$ и $A$ фиксируются заранее (в текущей реализации $a^o=35$ лет и $A=10$ лет).

Функция $h_g(a)$ описывает нелинейную часть возрастной поправки.
Чтобы не дублировать константную и линейную компоненты, которые уже представлены параметрами $\mu_g$ и $\gamma_g$,
сплайновая часть строится так, что выполняются ограничения
$$
h_g(a^o)=0,
\qquad
h'_g(a^o)=0.
$$
При такой конструкции $\mu_g$ и $\gamma_g$ отвечают за уровень и линейный тренд по возрасту, а $h_g(a)$ описывает только нелинейные отклонения.

Для каждого пола $g$ фиксируем набор B-сплайновых базисных функций по возрасту
$$
B_{g,1}(a),\dots,B_{g,K_g}(a),
$$
и представляем возрастную поправку в виде
$$
h_g(a)=\sum_{k=1}^{K_g}\beta_{g,k}\,B_{g,k}(a).
$$
Эквивалентная форма этой модели как штрафуемой регрессии со сплайновым штрафом на $h_g(a)$ используется при оценке параметров (REML) и при расчёте прогнозных величин. Вычислительная схема приводится в следующих разделах.

\subsection{LOY и production: выбор эталонов и ошибка эталона}

\subsubsection{Основные определения}

Напомним: $J$ — множество календарных годов, присутствующих в данных хотя бы для одной пары $(c,g)$.

Для пары $(c,g)$ и подмножества годов $J'\subseteq J$ обозначим через $n_{c,g}(J')$ число доступных финишей в годах из $J'$ после очистки данных (например, только старты со статусом OK и заданным временем финиша). В частности,
$$
n_{c,g}=n_{c,g}(J),
\qquad
n_{c,g,-j}=n_{c,g}(J\setminus\{j\}).
$$

Эталон для пары $(c,g)$, построенный по годам из $J'$, считается доступным, если выполнены условия
$$
n_{c,g}(J')\ge n_{\min},
\qquad
|S_{c,g}(J')|\ge m_{\min},
$$
где $S_{c,g}(J')$ — набор, используемый для вычисления эталона (см. ниже). В реализации проверяются оба условия. Можно взять
$$
n_{\min}=\left\lceil \frac{m_{\min}}{p_{\text{top}}}\right\rceil,
$$
тогда при $n\ge n_{\min}$ автоматически выполнено $\lfloor p_{\text{top}}\,n\rfloor\ge m_{\min}$.

Для цели $(c^\ast,g^\ast,j^\ast,a_{\text{new}})$ прогноз строится на основе согласованной пары
$$
(\hat R^{\text{use}},\tau^{2,\text{use}}),
$$
где $\hat R^{\text{use}}$ — эталон для нормировки, а $\tau^{2,\text{use}}$ — дисперсия процедурной ошибки его оценки на шкале $Y=\ln T$.

\subsubsection{Протокол top-отбора и набор $S$}

Пусть эталон строится по данным множества годов $J'$.

\paragraph{Top-отбор.}
Все доступные финиши пары $(c,g)$ в годах $J'$ сортируются по возрастанию времени $T$.
Затем выбирается доля $p_{\text{top}}$ быстрейших времён (в текущей реализации $p_{\text{top}}=0.05$, то есть $5\%$ самых быстрых).
Размер top-набора:
$$
m_{\text{top}}=\bigl\lfloor p_{\text{top}}\cdot n_{c,g}(J')\bigr\rfloor.
$$

Набор $S_{c,g}(J')$ формируется как первые $m_{\text{top}}$ значений после сортировки.
Если на границе $m_{\text{top}}$ есть совпадающие времена, используется детерминированный тай-брейк (например, по идентификатору старта), чтобы размер $|S_{c,g}(J')|=m_{\text{top}}$ был строго фиксирован.

Набор $S_{c,g}(J')$ является мультимножеством: повторы времён сохраняются.

\paragraph{Эталон.}
Эталон определяется как медиана по $S_{c,g}(J')$:
$$
\hat R_{c,g}(J')=\operatorname{med}\bigl(S_{c,g}(J')\bigr).
$$

Выбор медианы среди $5\%$ самых быстрых позволяет получить эталон, отражающий быстрый уровень, но устойчивый к единичным выбросам.

\subsubsection{Протоколы выбора $(\hat R^{\text{use}},\tau^{2,\text{use}})$}

Выбор пары зависит от режима и статуса года $j^\ast$. Обозначение $\hat R^{\text{use}}$ всегда соответствует одному из конкретных эталонов $\hat R_{c^\ast,g^\ast,-j^\ast}$ или $\hat R_{c^\ast,g^\ast}$ в зависимости от протокола.

\paragraph{Режим 1: LOY (leave-one-year-out).}
Все объекты для прогноза в году $j^\ast$ строятся по годам $J^{(-j^\ast)}=J\setminus\{j^\ast\}$. Используем:
$$
\hat R^{\text{use}}=\hat R_{c^\ast,g^\ast,-j^\ast}=\hat R_{c^\ast,g^\ast}(J\setminus\{j^\ast\}),
\qquad
\tau^{2,\text{use}}=\tau_{c^\ast,g^\ast,-j^\ast}^2.
$$

Процедурная дисперсия $\tau_{c^\ast,g^\ast,-j^\ast}^2$ оценивается бутстрэпом по мультимножеству $S_{c^\ast,g^\ast}(J\setminus\{j^\ast\})$. В каждой бутстрэп-реплике выполняется ресэмплирование с возвращением из $S_{c^\ast,g^\ast}(J\setminus\{j^\ast\})$, пересчитывается медиана $\hat R^{(b)}$, и дисперсия логарифмов $\ln \hat R^{(b)}$ по репликам даёт оценку $\tau_{c^\ast,g^\ast,-j^\ast}^2$. Процедура top-отбора внутри бутстрэп-реплик не повторяется.

Условия доступности:
$$
n_{c^\ast,g^\ast,-j^\ast}\ge n_{\min},
\qquad
|S_{c^\ast,g^\ast}(J\setminus\{j^\ast\})|\ge m_{\min}.
$$

\paragraph{Режим 2: Production, год $j^\ast$ присутствует в данных.}
Возрастная модель оценивается по всем годам $J$, но эталон для цели строится без года $j^\ast$:
$$
\hat R^{\text{use}}=\hat R_{c^\ast,g^\ast,-j^\ast}=\hat R_{c^\ast,g^\ast}(J\setminus\{j^\ast\}),
\qquad
\tau^{2,\text{use}}=\tau_{c^\ast,g^\ast,-j^\ast}^2.
$$

Набор $S_{c^\ast,g^\ast}(J\setminus\{j^\ast\})$ и бутстрэп для $\tau^2$ задаются так же, как в LOY. Условия доступности те же.

Отличие от LOY состоит только в том, что возрастная модель $h_g(a)$ оценивается по всем годам $J$ (включая $j^\ast$), а эталон строится по $J\setminus\{j^\ast\}$.

\paragraph{Режим 3: Production, год $j^\ast$ новый (отсутствует в данных).}
Эталон строится по всем доступным годам $J$:
$$
\hat R^{\text{use}}=\hat R_{c^\ast,g^\ast}=\hat R_{c^\ast,g^\ast}(J),
\qquad
\tau^{2,\text{use}}=\tau_{c^\ast,g^\ast}^2.
$$

Набор $S_{c^\ast,g^\ast}(J)$ формируется как top-доля $p_{\text{top}}$ от всех финишей пары $(c^\ast,g^\ast)$ в годах $J$, и медиана по $S_{c^\ast,g^\ast}(J)$ задаёт $\hat R_{c^\ast,g^\ast}(J)$. Дисперсия $\tau_{c^\ast,g^\ast}^2$ оценивается бутстрэпом по $S_{c^\ast,g^\ast}(J)$ аналогично режиму LOY.

Условия доступности:
$$
n_{c^\ast,g^\ast}\ge n_{\min},
\qquad
|S_{c^\ast,g^\ast}(J)|\ge m_{\min}.
$$

\subsubsection{Сводка режимов}

\begin{center}
\begin{tabular}{lccc}
\hline
Режим & Эталон $\hat R^{\text{use}}$ & Дисперсия $\tau^{2,\text{use}}$ & Годы для оценки $h_g(a)$ \\
\hline
LOY & $\hat R_{c^\ast,g^\ast,-j^\ast}$ & $\tau_{c^\ast,g^\ast,-j^\ast}^2$ & $J\setminus\{j^\ast\}$ \\
Production (год известен) & $\hat R_{c^\ast,g^\ast,-j^\ast}$ & $\tau_{c^\ast,g^\ast,-j^\ast}^2$ & $J$ \\
Production (год новый) & $\hat R_{c^\ast,g^\ast}$ & $\tau_{c^\ast,g^\ast}^2$ & $J$ \\
\hline
\end{tabular}
\end{center}

\subsubsection{Ошибка эталона и добавка $\delta$}

Определим логарифмическую ошибку эталона:
$$
\varepsilon_R=\ln R^{\text{use}}_{c^\ast,g^\ast}(j^\ast)-\ln \hat R^{\text{use}}_{c^\ast,g^\ast}(j^\ast),
$$
где $R^{\text{use}}_{c^\ast,g^\ast}(j^\ast)$ — идеализированный (ненаблюдаемый) эталон для выбранного протокола, а $\hat R^{\text{use}}_{c^\ast,g^\ast}(j^\ast)$ — его оценка по данным. В зависимости от протокола $\hat R^{\text{use}}_{c^\ast,g^\ast}(j^\ast)$ равен $\hat R_{c^\ast,g^\ast,-j^\ast}$ (режимы LOY и production с известным годом) или $\hat R_{c^\ast,g^\ast}$ (production с новым годом).

В практических расчётах ошибка эталона моделируется случайной добавкой на шкале $Y=\ln T$:
$$
\delta\sim N(0,\tau^{2,\text{use}}),
$$
где $\tau^{2,\text{use}}$ — процедурная дисперсия оценки эталона при фиксированном наборе $S$, согласованном с выбранным эталоном.

Нормальная модель для $\delta$ используется как рабочее приближение, чтобы компактно учитывать неопределённость нормировки и затем калибровать покрытие прогнозных интервалов в общей процедуре прогноза.

\subsubsection{Требование согласованности}

Пара $(\hat R^{\text{use}},\tau^{2,\text{use}})$ должна быть построена по одному и тому же набору данных и по одному и тому же протоколу получения $S$. Иными словами, $\hat R^{\text{use}}$ и $\tau^{2,\text{use}}$ должны ссылаться на один и тот же набор $S$ и на одно и то же множество годов (соответственно LOY или production). Смешивание объектов, построенных по разным наборам годов или по разным правилам формирования $S$, не даёт корректной интерпретации в рамках модели.

\subsubsection{Практические рекомендации для реализации}

\paragraph{Векторизация операций.}
Построение эталонов для всех пар $(c,g)$ и всех режимов — это операция, которая выполняется один раз на этапе подготовки данных, но включает обработку большого числа пар и годов. Критично использовать векторизованные операции для эффективности:

\begin{itemize}
\item \textbf{Группировка по $(c,g,J')$:} Используйте \texttt{groupby} (pandas/polars) для группировки финишей по тройке (трасса, пол, множество годов). Это позволит обработать все пары параллельно.

\item \textbf{Сортировка и отбор top:} Внутри каждой группы сортировка времён $T$ и взятие первых $m_{\text{top}}$ элементов выполняются векторизованно через \texttt{sort\_values} + \texttt{head} или \texttt{nsmallest}.

\item \textbf{Медиана:} Вычисление медианы по top-набору через \texttt{numpy.median} или \texttt{quantile(0.5)}.

\item \textbf{Бутстрэп:} Для каждого набора $S_{c,g}(J')$ бутстрэп-ресэмплирование выполняется через \texttt{numpy.random.choice(S, size=len(S), replace=True)} с фиксированным числом реплик (например, $B=1000$). Медианы по репликам вычисляются векторизованно, затем дисперсия логарифмов через \texttt{numpy.var(numpy.log(medians))}.
\end{itemize}

\paragraph{Детальный алгоритм построения эталонов.}
Вот пошаговый алгоритм для одной пары $(c,g)$ и множества годов $J'$:

\begin{enumerate}
\item \textbf{Фильтрация:} Отобрать все финиши с трассой $c$, полом $g$, годом из $J'$, статусом OK, заданным временем $T>0$.

\item \textbf{Проверка $n_{\min}$:} Вычислить $n_{c,g}(J')$ — число финишей после фильтрации. Если $n_{c,g}(J')<n_{\min}$, пометить эталон как недоступный и вернуть \texttt{None}.

\item \textbf{Top-отбор:} Сортировать финиши по $T$ (возрастание). Вычислить $m_{\text{top}}=\lfloor p_{\text{top}}\cdot n_{c,g}(J')\rfloor$. Взять первые $m_{\text{top}}$ времён. При совпадении времени на границе $m_{\text{top}}$ применить детерминированный тай-брейк по ID старта (минимальный ID).

\item \textbf{Проверка $m_{\min}$:} Если $m_{\text{top}}<m_{\min}$, пометить эталон как недоступный и вернуть \texttt{None}.

\item \textbf{Формирование $S$:} Сохранить top-набор $S_{c,g}(J')$ как массив времён (с повторами).

\item \textbf{Эталон:} Вычислить $\hat R_{c,g}(J')=\operatorname{med}(S_{c,g}(J'))$.

\item \textbf{Бутстрэп для $\tau^2$:} Для $b=1,\dots,B$ (например, $B=1000$):
   \begin{itemize}
   \item Ресэмплировать с возвращением из $S_{c,g}(J')$: $S^{(b)}=\texttt{sample}(S, |S|, \text{replace}=\text{True})$.
   \item Вычислить медиану реплики: $\hat R^{(b)}=\operatorname{med}(S^{(b)})$.
   \end{itemize}
   Вычислить дисперсию: $\tau_{c,g}^{2}(J')=\operatorname{Var}(\ln \hat R^{(b)})$ по $b=1,\dots,B$.

\item \textbf{Возврат:} Вернуть согласованную пару $(\hat R_{c,g}(J'),\tau_{c,g}^{2}(J'),S_{c,g}(J'))$ для дальнейшего использования.
\end{enumerate}

\paragraph{Кэширование результатов.}
Поскольку эталоны строятся один раз для всех режимов, результаты должны быть закэшированы в структуре данных (например, словарь или DataFrame) с ключом $(c,g,J')$. Это позволит избежать повторных вычислений при формировании целей для прогноза.

Типичная структура кэша:
\begin{verbatim}
{
  (course='VNM', gender=0, years=frozenset({2018,2019,...,2024})): 
    {'R_hat': 10234.5, 'tau2': 0.0012, 'S': array([...]), 'available': True},
  ...
}
\end{verbatim}

\paragraph{Число бутстрэп-реплик.}
Для оценки $\tau^2$ используется фиксированное число реплик $B=1000$. Это обеспечивает достаточную точность ($\sim 3\%$ стандартная ошибка для дисперсии) при разумных вычислительных затратах. Для top-наборов размера $m_{\text{top}}\sim 10{-}50$ одна реплика требует $O(m)$ операций для медианы, итого $O(Bm)\sim 10^4{-}10^5$ операций на пару $(c,g,J')$.

\paragraph{Параллелизация.}
Построение эталонов для разных пар $(c,g)$ независимо, поэтому процесс легко параллелится. Можно использовать \texttt{multiprocessing} (Python) или \texttt{parallel} (R) для обработки пар в параллельных процессах. Типичная производительность: $\sim 100{-}1000$ пар в секунду на одном ядре, в зависимости от размера top-наборов\footnote{MVP: для типичного набора данных ($\sim 100$ трасс $\times$ 2 пола $\times$ несколько режимов) построение всех эталонов занимает $<10$ секунд на современном CPU при векторизованной реализации.}

\subsubsection{Основные определения}

Напомним: $J$ — множество календарных годов, присутствующих в данных хотя бы для одной пары $(c,g)$.

Для пары $(c,g)$ и подмножества годов $J'\subseteq J$ обозначим через $n_{c,g}(J')$ число доступных финишей в годах из $J'$ после очистки данных (например, только старты со статусом OK и заданным временем финиша). В частности,
$$
n_{c,g}=n_{c,g}(J),
\qquad
n_{c,g,-j}=n_{c,g}(J\setminus\{j\}).
$$

Эталон для пары $(c,g)$, построенный по годам из $J'$, считается доступным, если выполнены условия
$$
n_{c,g}(J')\ge n_{\min},
\qquad
|S_{c,g}(J')|\ge m_{\min},
$$
где $S_{c,g}(J')$ — набор, используемый для вычисления эталона (см. ниже). В реализации проверяются оба условия. Можно взять
$$
n_{\min}=\left\lceil \frac{m_{\min}}{p_{\text{top}}}\right\rceil,
$$
тогда при $n\ge n_{\min}$ автоматически выполнено $\lfloor p_{\text{top}}\,n\rfloor\ge m_{\min}$.

Для цели $(c^\ast,g^\ast,j^\ast,a_{\text{new}})$ прогноз строится на основе согласованной пары
$$
(\hat R^{\text{use}},\tau^{2,\text{use}}),
$$
где $\hat R^{\text{use}}$ — эталон для нормировки, а $\tau^{2,\text{use}}$ — дисперсия процедурной ошибки его оценки на шкале $Y=\ln T$.

\subsubsection{Протокол top-отбора и набор $S$}

Пусть эталон строится по данным множества годов $J'$.

\paragraph{Top-отбор.}
Все доступные финиши пары $(c,g)$ в годах $J'$ сортируются по возрастанию времени $T$.
Затем выбирается доля $p_{\text{top}}$ быстрейших времён (в текущей реализации $p_{\text{top}}=0.05$, то есть $5\%$ самых быстрых).
Размер top-набора:
$$
m_{\text{top}}=\bigl\lfloor p_{\text{top}}\cdot n_{c,g}(J')\bigr\rfloor.
$$

Набор $S_{c,g}(J')$ формируется как первые $m_{\text{top}}$ значений после сортировки.
Если на границе $m_{\text{top}}$ есть совпадающие времена, используется детерминированный тай-брейк (например, по идентификатору старта), чтобы размер $|S_{c,g}(J')|=m_{\text{top}}$ был строго фиксирован.

Набор $S_{c,g}(J')$ является мультимножеством: повторы времён сохраняются.

\paragraph{Эталон.}
Эталон определяется как медиана по $S_{c,g}(J')$:
$$
\hat R_{c,g}(J')=\operatorname{med}\bigl(S_{c,g}(J')\bigr).
$$

Выбор медианы среди $5\%$ самых быстрых позволяет получить эталон, отражающий быстрый уровень, но устойчивый к единичным выбросам.

\subsubsection{Протоколы выбора $(\hat R^{\text{use}},\tau^{2,\text{use}})$}

Выбор пары зависит от режима и статуса года $j^\ast$. Обозначение $\hat R^{\text{use}}$ всегда соответствует одному из конкретных эталонов $\hat R_{c^\ast,g^\ast,-j^\ast}$ или $\hat R_{c^\ast,g^\ast}$ в зависимости от протокола.

\paragraph{Режим 1: LOY (leave-one-year-out).}
Все объекты для прогноза в году $j^\ast$ строятся по годам $J^{(-j^\ast)}=J\setminus\{j^\ast\}$. Используем:
$$
\hat R^{\text{use}}=\hat R_{c^\ast,g^\ast,-j^\ast}=\hat R_{c^\ast,g^\ast}(J\setminus\{j^\ast\}),
\qquad
\tau^{2,\text{use}}=\tau_{c^\ast,g^\ast,-j^\ast}^2.
$$

Процедурная дисперсия $\tau_{c^\ast,g^\ast,-j^\ast}^2$ оценивается бутстрэпом по мультимножеству $S_{c^\ast,g^\ast}(J\setminus\{j^\ast\})$. В каждой бутстрэп-реплике выполняется ресэмплирование с возвращением из $S_{c^\ast,g^\ast}(J\setminus\{j^\ast\})$, пересчитывается медиана $\hat R^{(b)}$, и дисперсия логарифмов $\ln \hat R^{(b)}$ по репликам даёт оценку $\tau_{c^\ast,g^\ast,-j^\ast}^2$. Процедура top-отбора внутри бутстрэп-реплик не повторяется.

Условия доступности:
$$
n_{c^\ast,g^\ast,-j^\ast}\ge n_{\min},
\qquad
|S_{c^\ast,g^\ast}(J\setminus\{j^\ast\})|\ge m_{\min}.
$$

\paragraph{Режим 2: Production, год $j^\ast$ присутствует в данных.}
Возрастная модель оценивается по всем годам $J$, но эталон для цели строится без года $j^\ast$:
$$
\hat R^{\text{use}}=\hat R_{c^\ast,g^\ast,-j^\ast}=\hat R_{c^\ast,g^\ast}(J\setminus\{j^\ast\}),
\qquad
\tau^{2,\text{use}}=\tau_{c^\ast,g^\ast,-j^\ast}^2.
$$

Набор $S_{c^\ast,g^\ast}(J\setminus\{j^\ast\})$ и бутстрэп для $\tau^2$ задаются так же, как в LOY. Условия доступности те же.

Отличие от LOY состоит только в том, что возрастная модель $h_g(a)$ оценивается по всем годам $J$ (включая $j^\ast$), а эталон строится по $J\setminus\{j^\ast\}$.

\paragraph{Режим 3: Production, год $j^\ast$ новый (отсутствует в данных).}
Эталон строится по всем доступным годам $J$:
$$
\hat R^{\text{use}}=\hat R_{c^\ast,g^\ast}=\hat R_{c^\ast,g^\ast}(J),
\qquad
\tau^{2,\text{use}}=\tau_{c^\ast,g^\ast}^2.
$$

Набор $S_{c^\ast,g^\ast}(J)$ формируется как top-доля $p_{\text{top}}$ от всех финишей пары $(c^\ast,g^\ast)$ в годах $J$, и медиана по $S_{c^\ast,g^\ast}(J)$ задаёт $\hat R_{c^\ast,g^\ast}(J)$. Дисперсия $\tau_{c^\ast,g^\ast}^2$ оценивается бутстрэпом по $S_{c^\ast,g^\ast}(J)$ аналогично режиму LOY.

Условия доступности:
$$
n_{c^\ast,g^\ast}\ge n_{\min},
\qquad
|S_{c^\ast,g^\ast}(J)|\ge m_{\min}.
$$

\subsubsection{Ошибка эталона и добавка $\delta$}

Определим логарифмическую ошибку эталона:
$$
\varepsilon_R=\ln R^{\text{use}}_{c^\ast,g^\ast}(j^\ast)-\ln \hat R^{\text{use}}_{c^\ast,g^\ast}(j^\ast),
$$
где $R^{\text{use}}_{c^\ast,g^\ast}(j^\ast)$ — идеализированный (ненаблюдаемый) эталон для выбранного протокола, а $\hat R^{\text{use}}_{c^\ast,g^\ast}(j^\ast)$ — его оценка по данным. В зависимости от протокола $\hat R^{\text{use}}_{c^\ast,g^\ast}(j^\ast)$ равен $\hat R_{c^\ast,g^\ast,-j^\ast}$ (режимы LOY и production с известным годом) или $\hat R_{c^\ast,g^\ast}$ (production с новым годом).

В практических расчётах ошибка эталона моделируется случайной добавкой на шкале $Y=\ln T$:
$$
\delta\sim N(0,\tau^{2,\text{use}}),
$$
где $\tau^{2,\text{use}}$ — процедурная дисперсия оценки эталона при фиксированном наборе $S$, согласованном с выбранным эталоном.

Нормальная модель для $\delta$ используется как рабочее приближение, чтобы компактно учитывать неопределённость нормировки и затем калибровать покрытие прогнозных интервалов в общей процедуре прогноза.

\subsubsection{Требование согласованности}

Пара $(\hat R^{\text{use}},\tau^{2,\text{use}})$ должна быть построена по одному и тому же набору данных и по одному и тому же протоколу получения $S$. Иными словами, $\hat R^{\text{use}}$ и $\tau^{2,\text{use}}$ должны ссылаться на один и тот же набор $S$ и на одно и то же множество годов (соответственно LOY или production). Смешивание объектов, построенных по разным наборам годов или по разным правилам формирования $S$, не даёт корректной интерпретации в рамках модели.

\subsubsection{Практические рекомендации для реализации}

\paragraph{Векторизация операций.}
Построение эталонов для всех пар $(c,g)$ и всех режимов — это операция, которая выполняется один раз на этапе подготовки данных, но включает обработку большого числа пар и годов. Критично использовать векторизованные операции для эффективности:

\begin{itemize}
\item \textbf{Группировка по $(c,g,J')$:} Используйте \texttt{groupby} (pandas/polars) для группировки финишей по тройке (трасса, пол, множество годов). Это позволит обработать все пары параллельно.

\item \textbf{Сортировка и отбор top:} Внутри каждой группы сортировка времён $T$ и взятие первых $m_{\text{top}}$ элементов выполняются векторизованно через \texttt{sort\_values} + \texttt{head} или \texttt{nsmallest}.

\item \textbf{Медиана:} Вычисление медианы по top-набору через \texttt{numpy.median} или \texttt{quantile(0.5)}.

\item \textbf{Бутстрэп:} Для каждого набора $S_{c,g}(J')$ бутстрэп-ресэмплирование выполняется через \texttt{numpy.random.choice(S, size=len(S), replace=True)} с фиксированным числом реплик (например, $B=1000$). Медианы по репликам вычисляются векторизованно, затем дисперсия логарифмов через \texttt{numpy.var(numpy.log(medians))}.
\end{itemize}

\paragraph{Детальный алгоритм построения эталонов.}
Вот пошаговый алгоритм для одной пары $(c,g)$ и множества годов $J'$:

\begin{enumerate}
\item \textbf{Фильтрация:} Отобрать все финиши с трассой $c$, полом $g$, годом из $J'$, статусом OK, заданным временем $T>0$.

\item \textbf{Проверка $n_{\min}$:} Вычислить $n_{c,g}(J')$ — число финишей после фильтрации. Если $n_{c,g}(J')<n_{\min}$, пометить эталон как недоступный и вернуть \texttt{None}.

\item \textbf{Top-отбор:} Сортировать финиши по $T$ (возрастание). Вычислить $m_{\text{top}}=\lfloor p_{\text{top}}\cdot n_{c,g}(J')\rfloor$. Взять первые $m_{\text{top}}$ времён. При совпадении времени на границе $m_{\text{top}}$ применить детерминированный тай-брейк по ID старта (минимальный ID).

\item \textbf{Проверка $m_{\min}$:} Если $m_{\text{top}}<m_{\min}$, пометить эталон как недоступный и вернуть \texttt{None}.

\item \textbf{Формирование $S$:} Сохранить top-набор $S_{c,g}(J')$ как массив времён (с повторами).

\item \textbf{Эталон:} Вычислить $\hat R_{c,g}(J')=\operatorname{med}(S_{c,g}(J'))$.

\item \textbf{Бутстрэп для $\tau^2$:} Для $b=1,\dots,B$ (например, $B=1000$):
   \begin{itemize}
   \item Ресэмплировать с возвращением из $S_{c,g}(J')$: $S^{(b)}=\texttt{sample}(S, |S|, \text{replace}=\text{True})$.
   \item Вычислить медиану реплики: $\hat R^{(b)}=\operatorname{med}(S^{(b)})$.
   \end{itemize}
   Вычислить дисперсию: $\tau_{c,g}^{2}(J')=\operatorname{Var}(\ln \hat R^{(b)})$ по $b=1,\dots,B$.

\item \textbf{Возврат:} Вернуть согласованную пару $(\hat R_{c,g}(J'),\tau_{c,g}^{2}(J'),S_{c,g}(J'))$ для дальнейшего использования.
\end{enumerate}

\paragraph{Кэширование результатов.}
Поскольку эталоны строятся один раз для всех режимов, результаты должны быть закэшированы в структуре данных (например, словарь или DataFrame) с ключом $(c,g,J')$. Это позволит избежать повторных вычислений при формировании целей для прогноза.

Типичная структура кэша:
\begin{verbatim}
{
  (course='VNM', gender=0, years=frozenset({2018,2019,...,2024})): 
    {'R_hat': 10234.5, 'tau2': 0.0012, 'S': array([...]), 'available': True},
  ...
}
\end{verbatim}

\paragraph{Число бутстрэп-реплик.}
Для оценки $\tau^2$ используется фиксированное число реплик $B=1000$. Это обеспечивает достаточную точность ($\sim 3\%$ стандартная ошибка для дисперсии) при разумных вычислительных затратах. Для top-наборов размера $m_{\text{top}}\sim 10{-}50$ одна реплика требует $O(m)$ операций для медианы, итого $O(Bm)\sim 10^4{-}10^5$ операций на пару $(c,g,J')$.

\paragraph{Параллелизация.}
Построение эталонов для разных пар $(c,g)$ независимо, поэтому процесс легко параллелится. Можно использовать \texttt{multiprocessing} (Python) или \texttt{parallel} (R) для обработки пар в параллельных процессах. Типичная производительность: $\sim 100{-}1000$ пар в секунду на одном ядре, в зависимости от размера top-наборов.

\footnote{MVP: для типичного набора данных ($\sim 100$ трасс $\times$ 2 пола $\times$ несколько режимов) построение всех эталонов занимает $<10$ секунд на современном CPU при векторизованной реализации.}

\subsection{Узлы сплайна по возрасту}

Возрастная функция $h_g(a)$ строится с использованием фиксированной сетки узлов по возрасту.
Узлы определяются один раз по обучающей выборке (в режиме LOY или production) и не изменяются в процессе оценки параметров.

Внутренние узлы задаются эмпирическими квантилями возрастов на уровнях $0.10$, $0.30$, $0.50$, $0.70$ и $0.90$.
Граничные узлы равны минимальному и максимальному возрасту в обучающей выборке.
Совпадение узлов (как квантильных между собой, так и внутренних с граничными) допускается и обрабатывается правилом слияния, описанным ниже.

В режиме LOY узлы строятся по годам $J^{(-j^\ast)}=J\setminus\{j^\ast\}$.
В список возрастов включаются только те наблюдения, для которых можно вычислить нормированное значение $z_r$ в LOY-режиме.
То есть для пары $(c,g)$ наблюдения должен быть доступен эталон нормировки, построенный по годам $J^{(-j^\ast)}$, и потому должен существовать $\hat R_{c,g}\!\bigl(J^{(-j^\ast)}\bigr)$.
Затем для каждого пола $g$ из каждой тройки (участник, год, трасса) оставляется не более одного старта, чтобы один участник не вносил несколько наблюдений в одну и ту же ситуацию.
По возрастам оставшихся наблюдений формируется выборка для вычисления квантилей.
На этапе построения узлов не применяется фильтрация по значениям $z_r$: узлы определяются только по возрастам.

В режиме production узлы строятся по тому же алгоритму, но по всем годам $J$.
Правила отбора наблюдений и фильтрации те же.

Для повышения устойчивости применяется детерминированное слияние узлов.
После начального построения узлы упорядочиваются по возрасту.
Если расстояние между двумя соседними узлами меньше $\Delta_{\min}$ лет (в текущей реализации $\Delta_{\min}=1$), они заменяются одним узлом со значением, равным среднему этих двух узлов.
После каждого слияния узлы переупорядочиваются, и процесс повторяется до тех пор, пока все расстояния между соседними узлами не меньше $\Delta_{\min}$.

Обозначим через $K^{\text{(inner)}}$ число внутренних узлов после завершения слияния (граничные узлы при этом не учитываются).
Требуется, чтобы выполнялось условие
$$
K^{\text{(inner)}}\ge K^{\text{(inner)}}_{\min},
\qquad
K^{\text{(inner)}}_{\min}=3.
$$
Если условие не выполнено, узловая конфигурация признаётся вырожденной, и оценка возрастной функции $h_g(a)$ для данного пола $g$ в этом режиме считается недоступной.

\subsection{Оценка возрастной модели по REML}

\subsubsection{Подготовка обучающей выборки}

Для фиксированного пола $g$ оценка возрастной функции $h_g(a)$ выполняется по обучающей выборке.
В режиме LOY для целевого года $j^\ast$ обучающая выборка формируется по годам $J^{(-j^\ast)}=J\setminus\{j^\ast\}$,
а в рабочем режиме (production) по всем годам~$J$.

Для каждого наблюдения $r$ из обучающей выборки вычисляется нормированное значение
$$
z_r = \ln T_r - \ln \hat R^{\text{use}}_{c_r,g_r}\!\bigl(j_r\bigr),
$$
где эталон $\hat R^{\text{use}}$ выбран согласно протоколу для данного режима (см. раздел про выбор эталонов).

\paragraph{MAD-винзоризация обучающих значений.}
Перед построением регрессионной модели к обучающим значениям $z_r$ применяется MAD-винзоризация для ограничения влияния редких крупных выбросов.
Винзоризация выполняется один раз для каждого пола $g$ по его обучающей выборке и не пересчитывается в процессе оптимизации параметров сглаживания.

Определим медиану и медианное абсолютное отклонение:
$$
m_z = \operatorname{med}_{r: g(r)=g^\ast}(z_r),
\qquad
\mathrm{MAD}_z = \operatorname{med}_{r: g(r)=g^\ast} |z_r - m_z|,
$$
где индекс $r$ пробегает все обучающие наблюдения пола $g^\ast$ в данном режиме.

Если $\mathrm{MAD}_z = 0$ (вырожденный случай: все $z_r$ совпадают), винзоризация не применяется и полагается $z_r^{\text{win}} = z_r$ для всех наблюдений.

Если $\mathrm{MAD}_z > 0$, каждое значение $z_r$ заменяется обрезанным:
$$
z_r^{\text{win}}
=
\begin{cases}
m_z + K_z\,\mathrm{MAD}_z, & \text{если } z_r > m_z + K_z\,\mathrm{MAD}_z, \\
m_z - K_z\,\mathrm{MAD}_z, & \text{если } z_r < m_z - K_z\,\mathrm{MAD}_z, \\
z_r, & \text{иначе},
\end{cases}
$$
где коэффициент винзоризации $K_z=3$ фиксирован.\footnote{MVP: $K_z$ фиксирован как 3. Позже можно сделать настраиваемым параметром конфигурации.}

Возраст $a_r$ и нормированный возраст $x_r=(a_r-a^o)/A$ при этом не изменяются.

Далее для построения модели используются винзоризованные значения $z_r^{\text{win}}$.

\subsubsection{Центрированный B-сплайн-базис}

Возрастная функция $h_g(a)$ строится как линейная комбинация кубических B-сплайновых базисных функций по узлам, определённым в предыдущем разделе.

Пусть $t_{g,0}, t_{g,1}, \dots, t_{g,m_g}$ — узлы для пола $g$ после слияния (включая граничные), где $t_{g,0}=a_{\min}$ и $t_{g,m_g}=a_{\max}$.
Для кубических B-сплайнов с этими узлами число базисных функций равно
$$
K_g = m_g + 3.
$$

Обозначим исходные (нецентрированные) базисные функции через $B_{g,k}(a)$, $k=1,\dots,K_g$.
Они определяются стандартной рекуррентной формулой для кубических B-сплайнов степени $d=3$ с расширенной узловой последовательностью
$$
\tau_{g,1},\dots,\tau_{g,K_g+4},
$$
где первые $4$ узла равны $t_{g,0}$, средние узлы совпадают с внутренними $t_{g,1},\dots,t_{g,m_g-1}$, последние $4$ узла равны $t_{g,m_g}$.

Любая линейная комбинация исходных базисных функций задаёт функцию
$$
h_g(a) = \sum_{k=1}^{K_g} \alpha_{g,k}\,B_{g,k}(a).
$$

\paragraph{Центрирование в точке $a^o$.}
Для предотвращения коллинеарности с константой $\mu_g$ и линейным трендом $\gamma_g x$ в регрессионной модели требуется, чтобы сплайновая часть $h_g(a)$ удовлетворяла условиям
$$
h_g(a^o)=0,
\qquad
h'_g(a^o)=0,
$$
где $a^o=35$ — опорный возраст (фиксирован в MVP).\footnote{MVP: $a^o=35$ фиксирован. Позже можно сделать параметром конфигурации и/или выбирать по данным, но центрирование должно оставаться детерминированным.}

Эти два линейных ограничения на коэффициенты $\alpha_g$ можно записать в матричном виде:
$$
D_g \alpha_g = 0,
$$
где $D_g$ — матрица $2\times K_g$ с элементами
$$
D_g[1,k] = B_{g,k}(a^o),
\qquad
D_g[2,k] = B'_{g,k}(a^o).
$$

Для численной реализации строим рабочий базис $b_{g,1}(x),\dots,b_{g,K_g-2}(x)$, живущий в подпространстве, удовлетворяющем этим ограничениям.
Это достигается выбором матрицы перехода $C_g$ размера $K_g\times(K_g-2)$, такой что:
\begin{itemize}
\item $D_g C_g = 0$,
\item столбцы $C_g$ ортонормированы.
\end{itemize}

Один из стандартных способов построения $C_g$:
\begin{enumerate}
\item Выполнить QR-разложение $D_g^\top = Q_g R_g$.
\item Взять последние $K_g-2$ столбца $Q_g$ как матрицу $C_g$.
\end{enumerate}

Тогда центрированные базисные функции задаются как
$$
b_{g,k}(x) = \sum_{\ell=1}^{K_g} C_{g,\ell k}\,B_{g,\ell}(a(x)),
\qquad
k=1,\dots,K_g-2,
$$
где $a(x)=a^o+A\cdot x$ — обратный переход от нормированного возраста к исходному.

Связь коэффициентов:
$$
h_g(a) = \sum_{k=1}^{K_g} \alpha_{g,k}\,B_{g,k}(a)
=
\sum_{k=1}^{K_g-2} \beta_{g,k}\,b_{g,k}(x(a)),
\qquad
\alpha_g = C_g\,\beta_g.
$$


\subsubsection{Штрафуемая линейная модель}

Для пола $g$ собирается матрица объясняющих переменных $W_g$ размера $n_g\times p_g$, где:
\begin{itemize}
\item $n_g$ — число обучающих наблюдений пола $g$ в данном режиме,
\item $p_g = 2 + (K_g-2) = K_g$ — число параметров (константа, линейный тренд, $(K_g-2)$ сплайновых коэффициентов).
\end{itemize}

Каждая строка матрицы $W_g$ соответствует одному наблюдению $r$ и имеет вид
$$
W_g[r,:] = \bigl[1,\ x_r,\ b_{g,1}(x_r),\ b_{g,2}(x_r),\ \dots,\ b_{g,K_g-2}(x_r)\bigr],
$$
где $x_r=(a_r-a^o)/A$ — нормированный возраст наблюдения $r$.

Вектор параметров модели:
$$
\theta_g=\begin{pmatrix}\mu_g \\ \gamma_g \\ \beta_g\end{pmatrix},
\qquad
\beta_g\in\mathbb{R}^{K_g-2}.
$$

Вектор наблюдений $\mathbf{z}_g\in\mathbb{R}^{n_g}$ состоит из винзоризованных значений $z_r^{\text{win}}$ обучающей выборки пола $g$ (в том же порядке, что и строки $W_g$).

Оценка параметров при фиксированном параметре сглаживания $\lambda>0$ задаётся штрафуемой задачей наименьших квадратов:
$$
\hat\theta_g(\lambda)
=
\arg\min_{\theta_g}
\Bigl\{
\|\mathbf{z}_g - W_g\theta_g\|^2 + \lambda\,\|L_g\theta_g\|^2
\Bigr\},
$$
где $L_g$ — матрица-корень полной матрицы штрафа $K^{\text{full}}_g$:
$$
L_g^\top L_g = K^{\text{full}}_g.
$$

\subsubsection{Матрица штрафа}

Штраф контролирует кривизну функции $h_g(a)$ и задаётся квадратичной формой второй производной.

\paragraph{Исходная матрица штрафа $K^{\text{raw}}_g$.}
В координатах исходного базиса $B_{g,k}(a)$ квадратичный функционал кривизны имеет вид
$$
J_g(\alpha_g)
=
\int_{a_{\min}}^{a_{\max}} \bigl(h_g''(a)\bigr)^2 \, da
=
\alpha_g^\top K^{\text{raw}}_g \alpha_g,
$$
где элементы матрицы $K^{\text{raw}}_g$ размера $K_g\times K_g$ определяются как
$$
\bigl(K^{\text{raw}}_g\bigr)_{k\ell}
=
\int_{a_{\min}}^{a_{\max}} B_{g,k}''(a)\,B_{g,\ell}''(a)\,da.
$$

Для кубических B-сплайнов вторая производная $B_{g,k}''(a)$ линейна на каждом интервале $[t_{g,i},t_{g,i+1}]$:
$$
B_{g,k}''(a) = c_{i,k}^{(0)} + c_{i,k}^{(1)}(a-t_{g,i}),
\qquad
a\in[t_{g,i},t_{g,i+1}],
$$
где коэффициенты $c_{i,k}^{(0)}$ и $c_{i,k}^{(1)}$ вычисляются из рекуррентных формул для производных B-сплайнов или эквивалентной библиотечной процедуры.

Интеграл по интервалу $[t_{g,i},t_{g,i+1}]$ вычисляется как
$$
\int_{t_{g,i}}^{t_{g,i+1}} B_{g,k}''(a)\,B_{g,\ell}''(a)\,da
=
\int_{t_{g,i}}^{t_{g,i+1}}
\bigl(c_{i,k}^{(0)}+c_{i,k}^{(1)}(a-t_{g,i})\bigr)
\bigl(c_{i,\ell}^{(0)}+c_{i,\ell}^{(1)}(a-t_{g,i})\bigr)
\,da.
$$
Полная матрица штрафа представляет собой сумму вкладов по интервалам:
$$
K^{\text{raw}}_g = \sum_{i=0}^{m_g-1} K^{(i)}_g.
$$

Из-за локальной поддержки кубических B-сплайнов каждый базисный элемент
$B_{g,k}(a)$ ненулевой только на ограниченном числе соседних интервалов по узлам.
Следовательно, вторые производные $B''_{g,k}(a)$ и $B''_{g,\ell}(a)$ имеют
пересекающиеся носители лишь тогда, когда индексы $k$ и $\ell$ близки.

Поэтому элемент матрицы штрафа
\[
(K^{\mathrm{raw}}_g)_{k\ell}
=
\int B''_{g,k}(a)\,B''_{g,\ell}(a)\,da
\]
равен нулю при $|k-\ell|>2$.
Иными словами, ненулевые элементы $K^{\mathrm{raw}}_g$ расположены только
на главной диагонали и двух соседних диагоналях по обе стороны от неё.
Тем самым матрица $K^{\mathrm{raw}}_g$ является трёхдиагональной матрицей с полушириной ленты~$2$
\footnote{MVP: допускается вычислять $K^{\text{raw}}_g$ через стандартные библиотечные B-сплайны (например, \texttt{scipy.interpolate.BSpline}) и численное интегрирование по интервалам. Позже можно заменить на аналитические формулы для ускорения, при сохранении того же функционала $J_g(\alpha_g)$ в пределах численной точности.}.

\paragraph{Штраф в рабочих координатах $K^{\beta}_g$.}
Центрированный рабочий базис связан с исходным через $\alpha_g = C_g\,\beta_g$.
Матрица штрафа в рабочих координатах определяется как
$$
K^{\beta}_g = C_g^\top K^{\text{raw}}_g\,C_g,
$$
и имеет размер $(K_g-2)\times(K_g-2)$.

\paragraph{Регуляризация $K^{\beta}_g$.}
Для численной устойчивости применяется спектральная регуляризация.
Выполним спектральное разложение:
$$
K^{\beta}_g = U_g \Lambda_g U_g^\top,
$$
где $U_g$ — ортогональная матрица собственных векторов, а $\Lambda_g$ — диагональная матрица собственных значений.

Определим порог:
$$
\varepsilon_\Lambda = 10^{-10}\,\max\bigl(1,\ \max_{i=1,\dots,K_g-2} \Lambda_{g,ii}\bigr).
$$
Если существует $i$ такое, что $\Lambda_{g,ii} < -\varepsilon_\Lambda$, конфигурация узлов и базиса объявляется недопустимой.

Для каждого $i$ полагаем
$$
\widetilde\Lambda_{g,ii}
=
\begin{cases}
\Lambda_{g,ii}, & \text{если } |\Lambda_{g,ii}| \ge \varepsilon_\Lambda, \\
0, & \text{если } |\Lambda_{g,ii}| < \varepsilon_\Lambda,
\end{cases}
$$
и определяем
$$
\widetilde{K}^{\beta}_g = U_g \widetilde\Lambda_g U_g^\top.
$$
\footnote{MVP: для спектрального разложения использовать \texttt{numpy.linalg.eigh} (симметричная матрица). Проверку знака собственных значений выполнять через порог $\varepsilon_\Lambda$.}

\paragraph{Полная матрица штрафа $K^{\text{full}}_g$.}
Полная матрица штрафа размера $p_g\times p_g$ имеет блочно-диагональный вид:
$$
K_g^{\text{full}} =
\begin{pmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & \widetilde{K}^{\beta}_g
\end{pmatrix}.
$$

\paragraph{Построение матрицы-корня $L_g$.}
Обозначим через $I_+$ множество индексов $i\in\{1,\dots,K_g-2\}$, для которых $\widetilde\Lambda_{g,ii}>0$, и $r_g=|I_+|$.
Пусть $U_{g,+}$ — матрица столбцов $U_g$, соответствующих $I_+$, а $\widetilde\Lambda_{g,+}$ — диагональная матрица положительных собственных значений.
Определим
$$
L^{\beta}_g = \widetilde\Lambda_{g,+}^{1/2} U_{g,+}^\top,
$$
тогда $(L^{\beta}_g)^\top L^{\beta}_g = \widetilde{K}^{\beta}_g$.
Полная матрица-корень $L_g$ размера $r_g\times p_g$ формируется как
$$
L_g =
\begin{pmatrix}
0_{r_g\times 2} & L^{\beta}_g
\end{pmatrix},
$$
и удовлетворяет $L_g^\top L_g = K_g^{\text{full}}$.

\subsubsection{REML-критерий и выбор $\lambda_g$}

Для заданного $\lambda>0$ задача
$$
\min_{\theta_g} \|\mathbf{z}_g - W_g\theta_g\|^2 + \lambda\,\|L_g\theta_g\|^2
$$
эквивалентна решению расширенной системы наименьших квадратов
$$
\begin{pmatrix}
W_g \\
\sqrt{\lambda}\,L_g
\end{pmatrix}
\theta_g
\approx
\begin{pmatrix}
\mathbf{z}_g \\
0
\end{pmatrix}.
$$

Обозначим
$$
\widetilde{W}_g(\lambda) =
\begin{pmatrix}
W_g \\
\sqrt{\lambda}\,L_g
\end{pmatrix},
$$
размер $(n_g+r_g)\times p_g$.

Выполним QR-разложение:
$$
\widetilde{W}_g(\lambda) =
Q_g(\lambda)
\begin{pmatrix}
R^{\text{qr}}_g(\lambda) \\
0
\end{pmatrix},
$$
где $R^{\text{qr}}_g(\lambda)$ — верхнетреугольная матрица размера $p_g\times p_g$.

Оценка $\hat\theta_g(\lambda)$ вычисляется решением треугольной системы, соответствующей QR-разложению:
$$
R^{\text{qr}}_g(\lambda)\,\hat\theta_g(\lambda) = \bigl(Q_g(\lambda)^\top \mathbf y_g(\lambda)\bigr)_{[1:p_g]},
\qquad
\mathbf y_g(\lambda)=
\begin{pmatrix}
\mathbf{z}_g \\
0
\end{pmatrix}.
$$
\footnote{MVP: использовать \texttt{numpy.linalg.qr} и \texttt{scipy.linalg.solve\_triangular}. Важно фиксировать соглашение о знаках диагонали $R^{\text{qr}}_g(\lambda)$ так, чтобы диагональные элементы были неотрицательными.}

\paragraph{Остаточная сумма квадратов и эффективное число параметров.}
Остаточная сумма квадратов:
$$
\mathrm{RSS}_g(\lambda) = \|\mathbf{z}_g - W_g \hat\theta_g(\lambda)\|^2.
$$

Эффективное число параметров вычисляется через матрицу $M_g(\lambda)$ размера $p_g\times n_g$, определяемую из треугольной системы
$$
\bigl(R^{\text{qr}}_g(\lambda)\bigr)^\top M_g(\lambda) = W_g^\top,
$$
после чего задаётся
$$
\mathrm{edf}_g(\lambda) = \|M_g(\lambda)\|_F^2.
$$
\footnote{MVP: решать систему для $M_g(\lambda)$ по столбцам через \texttt{solve\_triangular}, затем считать $\mathrm{edf}_g(\lambda)$ как сумму квадратов элементов (или как $\operatorname{tr}(M_g M_g^\top)$). Позже можно оптимизировать вычисление $\mathrm{edf}$, но формула должна оставаться эквивалентной.}

\paragraph{REML-критерий.}
Оценка дисперсии при фиксированном $\lambda$:
$$
\hat\sigma_g^2(\lambda)
=
\frac{\mathrm{RSS}_g(\lambda)}{n_g - \mathrm{edf}_g(\lambda)}.
$$

REML-критерий:
$$
\mathrm{REML}_g(\lambda)
=
\bigl(n_g - \mathrm{edf}_g(\lambda)\bigr)\log \hat\sigma_g^2(\lambda)
+
2\sum_{k=1}^{p_g} \log\bigl|R^{\text{qr}}_{g,kk}(\lambda)\bigr|.
$$

Вводится численный порог вырождения
$$
\varepsilon_R=10^{-12}.
$$
Если существует $k$ такое, что $|R^{\text{qr}}_{g,kk}(\lambda)| < \varepsilon_R$, соответствующее $\lambda$ исключается из рассмотрения.

\paragraph{Оптимизация по $\lambda$.}
Оптимальное значение выбирается как
$$
\hat\lambda_g
=
\arg\min_{\lambda \in [\lambda_{\min},\lambda_{\max}]}
\mathrm{REML}_g(\lambda),
$$
где границы фиксированы:
$$
\lambda_{\min}=10^{-8},
\qquad
\lambda_{\max}=10^{8}.
$$

Поиск ведётся по $\eta=\log_{10}\lambda$ на интервале $[-8,8]$.
Значение $\lambda$ исключается из рассмотрения, если выполнено хотя бы одно условие:
\begin{itemize}
\item $\nu_g(\lambda) = n_g - \mathrm{edf}_g(\lambda) \le \nu_{\min}$ при $\nu_{\min}=3$,
\item $|R^{\text{qr}}_{g,kk}(\lambda)| < \varepsilon_R$ для некоторого $k$,
\item $\mathrm{edf}_g(\lambda) > n_g - 1$.
\end{itemize}
Если ни одно $\lambda$ не проходит фильтры, оценка $h_g(a)$ для данного пола $g$ в этом режиме объявляется недоступной.\footnote{MVP: оптимизацию по $\eta=\log_{10}\lambda$ можно делать методом Брента (\texttt{scipy.optimize.minimize\_scalar}, метод \texttt{brent}) с обработкой недопустимых $\lambda$ через возврат $+\infty$ в критерии. Граничные решения $\lambda_{\min}$ или $\lambda_{\max}$ следует логировать как диагностический сигнал.}

\subsubsection{Масштаб и степени свободы}

Итоговый масштаб $\hat\sigma_g^2$ вычисляется с учётом вклада ошибки эталона.

\paragraph{Шаг 1: среднее $\overline{\tau^2}_g$.}
По обучающей выборке пола $g$ вычисляется среднее процедурных дисперсий ошибки эталона:
$$
\overline{\tau^2}_g
=
\frac{1}{n_g}
\sum_{r=1}^{n_g} \tau^{2,\text{use}}_r,
$$
где $\tau^{2,\text{use}}_r$ — процедурная дисперсия эталона, использованного для нормировки наблюдения $r$.
\footnote{MVP: для каждого обучающего наблюдения хранить ссылку на соответствующее значение $\tau^{2,\text{use}}$ (например, отдельной колонкой), затем брать среднее по наблюдениям. Это учитывает частоту использования разных трасс в обучении.}

\paragraph{Шаг 2: оптимизация REML.}
По обучающей выборке выполняется оптимизация REML, что даёт $\hat\lambda_g$ и
$$
\hat\sigma^{2,\text{REML}}_g
=
\frac{\mathrm{RSS}_g(\hat\lambda_g)}
     {n_g - \mathrm{edf}_g(\hat\lambda_g)}.
$$

\paragraph{Шаг 3: корректировка масштаба.}
Рабочий масштаб:
$$
\hat\sigma_g^2 =
\max\bigl(0,\ \hat\sigma^{2,\text{REML}}_g - \overline{\tau^2}_g\bigr).
$$
Если $\hat\sigma^{2,\text{REML}}_g \le \overline{\tau^2}_g$, полагается $\hat\sigma_g^2 = 0$.

\paragraph{Шаг 4: степени свободы.}
Степени свободы:
$$
\nu_g = n_g - \mathrm{edf}_g(\hat\lambda_g).
$$
Если $\nu_g \le \nu_{\min}=3$, оценка возрастной функции $h_g(a)$ для данного пола $g$ в этом режиме считается недоступной.

\paragraph{Итоговые оценки для пола $g$.}
После успешного завершения процедуры для пола $g$ в данном режиме получаем:
\begin{itemize}
\item $\hat\theta_g = (\hat\mu_g,\hat\gamma_g,\hat\beta_g)^\top$,
\item $\hat\sigma_g^2$,
\item $\nu_g$,
\item $\hat\lambda_g$.
\end{itemize}

Эти оценки используются далее для построения прогнозного распределения.

\subsection{Прогноз на нормированной шкале $Z$ и переход к шкале времени}

\subsubsection{Условия доступности прогноза}

Прогноз с учётом возрастной поправки строится для цели $(c^\ast,j^\ast,g,a_{\text{new}})$ и считается доступным только если выполнены все следующие условия:

\begin{enumerate}
\item Для пола $g$ в выбранном режиме (LOY или production) доступны оценки:
\begin{itemize}
\item вектор параметров $\hat\theta_g = (\hat\mu_g,\hat\gamma_g,\hat\beta_g)^\top$,
\item рабочий масштаб $\hat\sigma_g^2$,
\item степени свободы $\nu_g$,
\item оптимальный параметр сглаживания $\hat\lambda_g$,
\item верхнетреугольная матрица $R^{\text{qr}}_g(\hat\lambda_g)$ из QR-разложения расширенной системы при $\lambda=\hat\lambda_g$.
\end{itemize}

\item Возраст $a_{\text{new}}$ лежит в диапазоне граничных узлов сплайна для пола $g$ в этом режиме:
$$
t_{g,0} \le a_{\text{new}} \le t_{g,m_g},
$$
где $t_{g,0}$ и $t_{g,m_g}$ — минимальный и максимальный узлы после слияния. Экстраполяция по возрасту не выполняется.

\item Для цели $(c^\ast,j^\ast,g)$ в том же режиме доступна согласованная пара $(\hat R^{\text{use}},\tau^{2,\text{use}})$, построенная по тому же протоколу выбора эталона. Смешивать оценки из разных режимов или разных топ-наборов запрещено.
\end{enumerate}

Если хотя бы одно условие нарушено, прогноз для данной цели объявляется недоступным.

\subsubsection{Вектор объясняющих переменных в точке прогноза}

Нормированный возраст в точке прогноза:
$$
x_{\text{new}} = \frac{a_{\text{new}} - a^o}{A},
$$
где $a^o=35$ и $A=10$ — параметры нормировки.

Вычислим значения центрированных базисных функций $b_{g,k}(x_{\text{new}})$, $k=1,\dots,K_g-2$, в точке $x_{\text{new}}$.
Эти функции определены через линейное преобразование исходных B-сплайновых базисных функций матрицей $C_g$, построенной при формировании центрированного базиса.

Вектор регрессоров в точке прогноза:
$$
c_\ast = \begin{pmatrix} 
1 \\ 
x_{\text{new}} \\ 
b_{g,1}(x_{\text{new}}) \\
\vdots \\
b_{g,K_g-2}(x_{\text{new}})
\end{pmatrix}
\in\mathbb{R}^{p_g},
$$
где $p_g = K_g$ — число параметров модели.

\footnote{MVP: вычисление $b_{g,k}(x_{\text{new}})$ выполняется через исходные B-сплайновые функции $B_{g,\ell}(a_{\text{new}})$ и матрицу перехода $C_g$: $b_{g,k}(x_{\text{new}}) = \sum_{\ell=1}^{K_g} C_{g,\ell k} B_{g,\ell}(a_{\text{new}})$, где $a_{\text{new}} = a^o + A\cdot x_{\text{new}}$.}

\subsubsection{Точечный прогноз и прогностический масштаб на шкале $Z$}

\paragraph{Точечный прогноз.}
Условное среднее на нормированной шкале $Z$:
$$
\hat m_\ast = c_\ast^\top \hat\theta_g
=
\hat\mu_g + \hat\gamma_g x_{\text{new}} + \sum_{k=1}^{K_g-2} \hat\beta_{g,k} b_{g,k}(x_{\text{new}}).
$$

\paragraph{Прогностическая дисперсия.}
Для вычисления прогностической дисперсии используется верхнетреугольная матрица $R^{\text{qr}}_g(\hat\lambda_g)$ размера $p_g\times p_g$, полученная при QR-разложении расширенной системы для $\lambda=\hat\lambda_g$.

Для краткости обозначим $R_g = R^{\text{qr}}_g(\hat\lambda_g)$.

Вводится численный порог устойчивости:
$$
\varepsilon_R = 10^{-12}.
$$

Если существует диагональный элемент $k$ такой, что $|R_{g,kk}| < \varepsilon_R$, система считается вырожденной, и прогноз объявляется недоступным.

Определим векторы $u,w\in\mathbb{R}^{p_g}$ через последовательное решение двух треугольных систем:
\begin{equation}
R_g^\top u = c_\ast,
\label{eq:pred_u}
\end{equation}
\begin{equation}
R_g w = u.
\label{eq:pred_w}
\end{equation}

Прогностическая дисперсия на шкале $Z$:
$$
s_{\text{pred}}^2 = \hat\sigma_g^2 \bigl(1 + c_\ast^\top w \bigr).
$$

\textbf{Интерпретация:} Величина $c_\ast^\top w$ — это стандартный член прогностической дисперсии в линейной регрессии, соответствующий неопределённости оценки параметров $\hat\theta_g$. Первое слагаемое $\hat\sigma_g^2$ соответствует остаточной вариации (новое наблюдение вокруг своего среднего).

Теоретически при невырожденной $R_g$ величина $c_\ast^\top w \ge 0$, поэтому $1 + c_\ast^\top w > 0$. В реализации выполняется диагностическая проверка:
$$
1 + c_\ast^\top w > 0.
$$
Если численно получается $1 + c_\ast^\top w \le 0$, прогноз объявляется недоступным.

\footnote{MVP: решение треугольных систем~\eqref{eq:pred_u} и~\eqref{eq:pred_w} выполняется через \texttt{scipy.linalg.solve\_triangular} с параметрами \texttt{lower=False} для $R_g$ и \texttt{lower=False, trans='T'} для $R_g^\top$. Проверка положительности $1+c_\ast^\top w$ критична для устойчивости.}

\subsubsection{Рабочее прогностическое распределение на шкале $Z$}

Рабочее прогностическое распределение задаётся как
$$
Z_{\text{new}} = \hat m_\ast + \kappa_g\, s_{\text{pred}}\, \xi,
\qquad
\xi \sim t_{\nu_g},
$$
где $t_{\nu_g}$ — распределение Стьюдента с $\nu_g$ степенями свободы, а $\kappa_g$ — калибровочный коэффициент.

\paragraph{Калибровочный коэффициент $\kappa_g$.} 
В режиме LOY используется $\kappa_g = 1$ (без калибровки). В рабочем режиме (production) используется фиксированное значение $\kappa_g$, полученное процедурой калибровки по эмпирическому покрытию прогнозных интервалов на LOY-данных. Калибровка выполняется отдельно для каждого пола $g$ и описана в отдельном разделе. В данной модели калибровка множителя $\kappa_g$ выполняется исключительно по эмпирическому покрытию прогнозных интервалов, полученных методом Монте-Карло. Аналитические $t$-интервалы и связанные с ними формулы для калибровки не используются. \footnote{MVP: допускается временно положить $\kappa_g=1$ в обоих режимах. Если калибровка включена, значения $\kappa_g$ должны храниться в конфигурации отдельно для каждого пола $g$ и использоваться без переоценки.}
\paragraph{Квантили на шкале $Z$.}
Квантиль уровня $\alpha$ для $Z_{\text{new}}$:
$$
Q_Z(\alpha) = \hat m_\ast + \kappa_g\, s_{\text{pred}}\, t_{\nu_g}(\alpha),
$$
где $t_{\nu_g}(\alpha)$ — квантиль уровня $\alpha$ распределения Стьюдента с $\nu_g$ степенями свободы.

\textbf{Важно:} Квантили на шкале $Z$ могут использоваться только для анализа неопределённости на нормированной шкале. Для получения квантилей на шкалах $Y=\ln T$ и $T$ прямое экспонентирование $\exp(Q_Z(\alpha))$ не применяется из-за несимметричности распределения и вклада ошибки эталона.

\subsubsection{Переход к шкале $Y=\ln T$ и шкале времени $T$}

Переход выполняется генеративно методом Монте-Карло с явным учётом ошибки эталона.

\paragraph{Генерация одной реализации.}
Для каждой Монте-Карло реплики $b=1,\dots,N$ независимо генерируются:
\begin{itemize}
\item $\xi^{(b)} \sim t_{\nu_g}$ — случайная величина Стьюдента,
\item $\delta^{(b)} \sim N(0,\tau^{2,\text{use}})$ — ошибка эталона,
\end{itemize}
после чего вычисляются:
$$
Z_{\text{new}}^{(b)} = \hat m_\ast + \kappa_g\, s_{\text{pred}}\, \xi^{(b)},
$$
$$
Y_{\text{new}}^{(b)} = \ln \hat R^{\text{use}} + Z_{\text{new}}^{(b)} + \delta^{(b)},
$$
$$
T_{\text{new}}^{(b)} = \exp\bigl(Y_{\text{new}}^{(b)}\bigr).
$$

Здесь $(\hat R^{\text{use}},\tau^{2,\text{use}})$ — согласованная пара эталона и его процедурной дисперсии, построенная для цели $(c^\ast,j^\ast,g)$ в том же режиме (LOY или production), что и возрастная модель.

\textbf{Критично:} Смешивать эталон из одного режима с возрастной моделью из другого режима запрещено. Например, если возрастная модель построена в LOY-режиме для года $j^\ast$, то эталон должен быть $\hat R_{c^\ast,g,-j^\ast}$, а не $\hat R_{c^\ast,g}$.

\paragraph{Число реплик и воспроизводимость.}
Число Монте-Карло реплик фиксировано:
$$
N = 20\,000.
$$


 Генератор псевдослучайных чисел инициализируется детерминированным seed на основе SHA-256 от сериализованного идентификатора цели и режима:
$$
\text{key} = \mathrm{repr}\bigl((c^\ast,j^\ast,g,a_{\text{new}},\text{mode})\bigr),
\qquad
\text{dig}=\mathrm{sha256}\!\bigl(\mathrm{utf8}(\text{key})\bigr),
$$
$$
\text{seed}=
\Bigl(\mathrm{int\_from\_bytes}\bigl(\text{dig}[0{:}8],\text{big}\bigr)\Bigr)\bmod 2^{32},
\qquad
\text{mode}\in\{\text{LOY},\text{production}\}.
$$
Здесь $\mathrm{utf8}(\cdot)$ означает кодирование строки в байты UTF-8, $\text{dig}[0{:}8]$ - первые 8 байт digest, а $\mathrm{int\_from\_bytes}(\cdot)$ - перевод байтов в неотрицательное целое.
 Это обеспечивает воспроизводимость прогноза при повторных вызовах с теми же входными данными.

\footnote{MVP: встроенную функцию \texttt{hash} Python использовать нельзя, так как она по умолчанию рандомизирована между запусками. Использовать только стабильный хеш, например \texttt{hashlib.sha256} с переводом \texttt{digest} в целое через \texttt{int.from\_bytes}.}

\subsubsection{Квантили на шкалах $Y$ и $T$}

Квантили на шкалах $Y$ и $T$ вычисляются по эмпирическим распределениям Монте-Карло выборок $\{Y_{\text{new}}^{(b)}\}_{b=1}^N$ и $\{T_{\text{new}}^{(b)}\}_{b=1}^N$.

\paragraph{Вычисление эмпирических квантилей.}
Для заданного уровня $\alpha\in(0,1)$ квантиль уровня $\alpha$ на шкале $Y$:
$$
Q_Y(\alpha) = \text{quantile}\bigl(\{Y_{\text{new}}^{(b)}\}_{b=1}^N,\ \alpha\bigr),
$$
где функция $\text{quantile}$ вычисляется по стандартному алгоритму интерполяции между порядковыми статистиками.

Аналогично для шкалы $T$:
$$
Q_T(\alpha) = \text{quantile}\bigl(\{T_{\text{new}}^{(b)}\}_{b=1}^N,\ \alpha\bigr).
$$

\footnote{MVP: использовать \texttt{numpy.quantile} с параметром \texttt{method='linear'} (интерполяция линейная между порядковыми статистиками). Этот метод соответствует типу 7 в R и обеспечивает непрерывность квантильной функции.}

\paragraph{Отчётные величины.}
Основные отчётные величины на шкале времени $T$:
\begin{itemize}
\item \textbf{Медиана:} $Q_T(0.5)$,
\item \textbf{Квантили для прогнозных интервалов:} например, $Q_T(0.05)$, $Q_T(0.16)$, $Q_T(0.84)$, $Q_T(0.95)$.
\end{itemize}

Математическое ожидание на шкале $T$ не используется из-за несимметричности распределения (логнормальный хвост справа).

\paragraph{Связь квантилей на разных шкалах.}
Квантили на шкалах $Y$ и $T$ связаны монотонным преобразованием:
$$
Q_T(\alpha) = \exp\bigl(Q_Y(\alpha)\bigr).
$$
Однако квантиль на шкале $Z$ не связан с квантилем на шкале $Y$ простым сдвигом из-за независимой добавки $\delta$:
$$
Q_Y(\alpha) \ne \ln \hat R^{\text{use}} + Q_Z(\alpha).
$$

\subsubsection{Граничные случаи и недоступность прогноза}

Прогноз для цели $(c^\ast,j^\ast,g,a_{\text{new}})$ объявляется недоступным, если выполнено хотя бы одно из условий:
\begin{itemize}
\item Возраст $a_{\text{new}}$ выходит за пределы граничных узлов сплайна для пола $g$ в выбранном режиме.
\item Для пола $g$ в выбранном режиме отсутствуют оценки $\hat\theta_g$, $\hat\sigma_g^2$, $\nu_g$, $\hat\lambda_g$, или матрица $R_g$.
\item Матрица $R_g$ вырождена: существует $k$ такое, что $|R_{g,kk}| < \varepsilon_R=10^{-12}$.
\item Прогностическая дисперсия отрицательна или нулевая: $1 + c_\ast^\top w \le 0$.
\item Для цели $(c^\ast,j^\ast,g)$ в том же режиме недоступна согласованная пара $(\hat R^{\text{use}},\tau^{2,\text{use}})$.
\item Несогласованность режимов: возрастная модель построена в одном режиме (LOY/production), а эталон запрошен из другого режима.
\end{itemize}

В случае недоступности прогноза система должна вернуть явный код ошибки с указанием причины (для диагностики).
\subsection{Численный расчёт прогноза методом Монте-Карло}

В этом разделе задаётся численный протокол метода Монте-Карло для вычисления прогнозных квантилей на шкалах $Y=\ln T$ и $T=\exp(Y)$.

Для цели $(c^\ast,g,j^\ast,a_{\text{new}})$ в выбранном режиме (LOY или production) считаются уже полученными следующие величины:
$$
\hat m_\ast,\ s_{\text{pred}},\ \nu_g,\ \kappa_g,\ 
\hat R^{\text{use}},\ \tau^{2,\text{use}}.
$$

Пара $(\hat R^{\text{use}},\tau^{2,\text{use}})$ построена по одному протоколу выбора эталона в одном режиме. Смешивание различных режимов или топ-наборов запрещено.

\subsubsection{Генеративная схема}

Фиксируется максимальный объём моделирования $N_{\max}$ (конкретное значение задано ниже). Генерируется последовательность независимых случайных пар
$$
\bigl(\xi^{(b)},\delta^{(b)}\bigr),
\qquad b=1,\dots,N_{\max},
$$
где
$$
\xi^{(b)}\sim t_{\nu_g},
\qquad
\delta^{(b)}\sim N\bigl(0,\tau^{2,\text{use}}\bigr).
$$

Для любого $N\le N_{\max}$ используются первые $N$ элементов этой последовательности.

Для каждой реплики $b=1,\dots,N$ вычисляются:
$$
Z_{\text{new}}^{(b)}=\hat m_\ast+\kappa_g s_{\text{pred}}\xi^{(b)},
$$
$$
Y_{\text{new}}^{(b)}=\ln \hat R^{\text{use}}+Z_{\text{new}}^{(b)}+\delta^{(b)},
\qquad
T_{\text{new}}^{(b)}=\exp\bigl(Y_{\text{new}}^{(b)}\bigr).
$$

Случайная добавка к логарифму времени финиша имеет вид $\kappa_g s_{\text{pred}}\xi^{(b)}+\delta^{(b)}$ и представляет собой сумму двух независимых компонент (рабочее допущение модели).

\subsubsection{Детерминизм и инициализация генератора}

Для воспроизводимости все случайные величины генерируются из детерминированного начального значения (seed), зависящего только от параметров цели.

\paragraph{Канонизация возраста.}
Возраст преобразуется в целое число для устранения неопределённости floating-point представления:
$$
a_\mu=\lfloor A^M a_{\text{new}}+0.5\rfloor,
$$
где $A^M=10^6$ — фиксированная константа. Канонизация с точностью $10^{-6}$ лет достаточна для практических целей. Другие способы канонизации не допускаются.

\paragraph{Формирование seed.}
Задаётся глобальная строковая константа (SALT):
$$
\texttt{SALT}=\texttt{<<LOY\_AGE\_MODEL\_v1>>}.
$$

SALT обеспечивает автоматическое изменение всех seed при изменении версии модели, даже для тех же целей.

Строится строка:
$$
s=\texttt{SALT}\,\vert\,c^\ast\,\vert\,g\,\vert\,j^\ast\,\vert\,a_\mu,
$$
где:
\begin{itemize}
\item $c^\ast$ — строковый идентификатор трассы (не содержит пробелов и символа `|`),
\item $g\in\{0,1\}$ — пол ($0$ для мужчин, $1$ для женщин),
\item $j^\ast$ — календарный год (целое число),
\item $a_\mu$ — канонизированный возраст (целое число),
\item разделитель — символ `|` (ASCII 124).
\end{itemize}

Все числовые величины сериализуются в десятичном формате без ведущих нулей. Строка кодируется в UTF-8 без BOM.

К строке $s$ применяется хеш-функция BLAKE2b без ключа с параметром $\texttt{digest\_size}=8$ байт. Полученный дайджест интерпретируется как беззнаковое 64-битное целое число в формате little-endian и используется как начальное значение генератора.

Одно и то же начальное значение применяется как в LOY-режиме, так и в production-режиме для одной и той же цели. Режим влияет на параметры модели $(\hat m_\ast, s_{\text{pred}}, \nu_g, \kappa_g)$, но не на последовательность $\bigl(\xi^{(b)},\delta^{(b)}\bigr)$.

\footnote{MVP: использовать \texttt{hashlib.blake2b} с параметром \texttt{digest\_size=8}. BLAKE2b выбран как более быстрая альтернатива SHA-256 при сохранении криптографической стойкости для наших целей. Инициализация генератора NumPy: \texttt{rng = numpy.random.Generator(numpy.random.PCG64(seed))}, затем генерация через \texttt{rng.standard\_t(nu\_g, size=N\_max)} и \texttt{rng.normal(0, sqrt(tau2\_use), size=N\_max)}.}

\subsubsection{Квантильный протокол}

Фиксируются параметры:
$$
\mathcal{P}_{\text{check}}=\{0.05,0.50,0.95\},
\qquad
\Delta_Y=0.002,
\qquad
N_{\min}=25\,000,
\qquad
N_{\max}=400\,000,
$$
где $N_{\max}=N_{\min}\cdot 2^k$ для целого $k\ge 0$ (в данном случае $k=4$), что обеспечивает целочисленное кратное при удвоении объёма. Эти значения считаются частью неизменяемой конфигурации модели. Изменение требует пересмотра всей схемы прогноза.

Множество $\mathcal{P}_{\text{check}}$ используется только для проверки сходимости адаптивной процедуры. Итоговые отчётные квантили могут включать дополнительные уровни (например, $0.16$ и $0.84$ для $\pm 1\sigma$ интервалов), которые вычисляются после остановки адаптивной процедуры по финальному объёму $N_{\text{final}}$.

\paragraph{Оценка квантилей на шкале $Y$.}
Пусть при объёме моделирования $N$ получена выборка $\{Y_{\text{new}}^{(b)}\}_{b=1}^N$, а отсортированные значения обозначены как $y_{(1)}\le\dots\le y_{(N)}$.

Для уровня $p\in(0,1)$ квантиль оценивается по схеме type 7 (R):
$$
h=1+(N-1)p.
$$

Если $h\le1$, полагается $\widehat q_p^{(N)}(Y)=y_{(1)}$.
Если $h\ge N$, полагается $\widehat q_p^{(N)}(Y)=y_{(N)}$.
Иначе при
$$
k=\lfloor h\rfloor,
\qquad 
\gamma=h-k
$$
определяется
$$
\widehat q_p^{(N)}(Y)=(1-\gamma)y_{(k)}+\gamma y_{(k+1)}.
$$

\footnote{MVP: использовать \texttt{numpy.quantile(..., method='linear')}, что эквивалентно type 7 в R. Не использовать другие методы интерполяции.}

Квантили на шкале времени вычисляются только через логарифмическую шкалу:
$$
\widehat q_p(T)=\exp\bigl(\widehat q_p(Y)\bigr).
$$

Прямой квантильный расчёт по выборке $\{T_{\text{new}}^{(b)}\}$ не используется для отчётных значений, поскольку квантили $T$ связаны с квантилями $Y$ монотонным преобразованием, а вычисления на логарифмической шкале численно более устойчивы.

\paragraph{Адаптивный выбор объёма моделирования.}
Процедура определяет минимальный объём $N$, при котором квантили стабилизируются с точностью $\Delta_Y$ на шкале $Y$:

\begin{enumerate}
\item Начальный объём: $N=N_{\min}$.
\item Генерируются первые $N$ пар $(\xi^{(b)},\delta^{(b)})$ и вычисляются квантили $\widehat q_p^{(N)}(Y)$ для всех $p\in\mathcal{P}_{\text{check}}$.
\item Увеличивается объём $N'=\min(2N,N_{\max})$. Добавляются пары с индексами $b=N+1,\dots,N'$ к уже сгенерированным (без повторной генерации ранее полученных пар).
\item Пересчитываются квантили $\widehat q_p^{(N')}(Y)$ по первым $N'$ значениям $Y_{\text{new}}^{(b)}$.
\item Определяется максимальное отклонение:
$$
\Delta_Y^{\text{obs}}
=\max_{p\in\mathcal{P}_{\text{check}}}
\bigl|\widehat q_p^{(N')}(Y)-\widehat q_p^{(N)}(Y)\bigr|.
$$
\item Если $\Delta_Y^{\text{obs}}\le\Delta_Y$, моделирование останавливается с финальным объёмом $N_{\text{final}}=N'$.
\item Если $\Delta_Y^{\text{obs}}>\Delta_Y$ и $N'<N_{\max}$, полагается $N\leftarrow N'$ и процедура повторяется с шага 3.
\item Если $\Delta_Y^{\text{obs}}>\Delta_Y$ при $N'=N_{\max}$, прогноз объявляется недоступным из-за недостаточной сходимости.
\end{enumerate}

После остановки адаптивной процедуры все отчётные квантили (включая дополнительные уровни вне $\mathcal{P}_{\text{check}}$) вычисляются по финальной выборке объёма $N_{\text{final}}$.

\footnote{MVP: случай недостаточной сходимости при $N_{\max}=400\,000$ указывает на проблемы с параметрами модели ($\nu_g$ слишком мало, $\tau^{2,\text{use}}$ слишком велико, или экстремальные значения). Требуется диагностика. Для типичных целей процедура останавливается при $N\approx 50\,000{-}100\,000$, что занимает $<1$ секунды на современном CPU.}

\subsubsection{Замечания по реализации}

Реализация может заранее сгенерировать массивы $\{\xi^{(b)}\}_{b=1}^{N_{\max}}$ и $\{\delta^{(b)}\}_{b=1}^{N_{\max}}$ сразу после инициализации генератора, а адаптивная часть использует префиксы этих массивов длины $N$. Это снижает риск случайной повторной генерации.

Число операций и объём памяти растут линейно по $N_{\max}$. Параметры $N_{\min}$, $N_{\max}$ и $\Delta_Y$ фиксируются один раз и не изменяются без пересмотра всей схемы прогноза.

Допускаются только такие оптимизации реализации, которые сохраняют:
\begin{itemize}
\item детерминированную инициализацию генератора по описанному протоколу,
\item единую последовательность случайных пар $\bigl(\xi^{(b)},\delta^{(b)}\bigr)$ при фиксированном seed,
\item описанный квантильный протокол type 7 на шкале $Y$.
\end{itemize}

Любые изменения, нарушающие воспроизводимость результатов при одинаковых входных данных, не допускаются.

\subsection{Калибровка покрытия и множитель $\kappa_g$}

Калибровка множителя $\kappa_g$ проводится по результатам LOY-валидации и служит для согласования ширины прогнозных интервалов по шкале $Y=\ln T$ с наблюдаемым эмпирическим покрытием.

В данной модели калибровка множителя $\kappa_g$ выполняется исключительно по эмпирическому покрытию прогнозных интервалов, полученных методом Монте-Карло. Аналитические $t$-интервалы и связанные с ними формулы для калибровки не используются. Это обеспечивает полную согласованность калибровки с механизмом построения отчётных интервалов.

\subsubsection{Определение покрытия}

Для фиксированного пола $g$ и значения множителя $\kappa$ под покрытием понимается эмпирическая доля LOY-случаев, для которых наблюдаемое значение
$$
Y_r^{\text{obs}} = \ln T_r
$$
попадает внутрь центрального $90$-процентного интервала прогноза по шкале $Y$.

Пусть $\mathcal{I}_g^{\text{LOY}}$ — множество всех LOY-случаев пола $g$, для которых прогноз признан доступным по всем условиям модели:
\begin{itemize}
\item доступность согласованной пары эталона $(\hat R^{\text{use}},\tau^{2,\text{use}})$,
\item доступность возрастной модели (оценки $\hat\theta_g$, $\hat\sigma_g^2$, $\nu_g$, матрицы $R_g$),
\item возраст в пределах граничных узлов сплайна,
\item устойчивость прогностической дисперсии ($1+c_\ast^\top w>0$),
\item успешное завершение адаптивной Монте-Карло процедуры (сходимость квантилей).
\end{itemize}

Для каждого $r \in \mathcal{I}_g^{\text{LOY}}$ и заданного $\kappa$ по Монте-Карло выборке $\{Y_r^{(b)}(\kappa)\}_{b=1}^{N_r}$ вычисляются квантили $\widehat q_{0.05,r}(\kappa)$ и $\widehat q_{0.95,r}(\kappa)$, где $N_r$ — финальный объём моделирования, определённый адаптивной процедурой для случая $r$.

Эмпирическое покрытие определяется как
$$
\widehat{\text{cov}}_g(\kappa)
=
\frac{1}{|\mathcal{I}_g^{\text{LOY}}|}
\sum_{r \in \mathcal{I}_g^{\text{LOY}}}
\mathbf{1}\Bigl\{
\widehat q_{0.05,r}(\kappa)
\le
Y_r^{\text{obs}}
\le
\widehat q_{0.95,r}(\kappa)
\Bigr\}.
$$

\subsubsection{Цель калибровки}

Цель калибровки состоит в подборе такого значения $\kappa_g$, при котором эмпирическое покрытие центрального $90$-процентного интервала по шкале $Y$ для пола $g$ максимально близко к номинальному:
$$
\widehat{\text{cov}}_g(\kappa_g) \approx 0.90.
$$

Калибровка проводится исключительно по результатам LOY-валидации. В режиме LOY для построения отчётных интервалов всегда используется $\kappa_g = 1$; калиброванное значение применяется только в рабочем режиме (production).

\subsubsection{Исходные данные LOY}

Для каждого LOY-случая $r \in \mathcal{I}_g^{\text{LOY}}$ считаются зафиксированными:
\begin{itemize}
\item наблюдаемое значение $Y_r^{\text{obs}}=\ln T_r$,
\item параметры прогноза $\hat m_r$, $s_{\text{pred},r}$,
\item степени свободы $\nu_{g,r}$ (могут различаться для разных LOY-годов),
\item согласованная пара эталона $(\hat R^{\text{use}}_r,\tau^{2,\text{use}}_r)$,
\item детерминированная последовательность пар
$$
\bigl(\xi_r^{(b)}, \delta_r^{(b)}\bigr),\quad b=1,\dots,N_{\max},
$$
где
$$
\xi_r^{(b)} \sim t_{\nu_{g,r}}, 
\qquad
\delta_r^{(b)} \sim N\bigl(0,\tau^{2,\text{use}}_r\bigr).
$$
\end{itemize}

Последовательности $\bigl(\xi_r^{(b)}, \delta_r^{(b)}\bigr)$ генерируются по детерминированному seed (согласно протоколу из раздела про Монте-Карло) и используются одни и те же для всех значений $\kappa$ в процессе калибровки. Повторная генерация случайных чисел при переборе $\kappa$ не выполняется.

\footnote{MVP: для экономии памяти можно не сохранять все последовательности, а регенерировать их из seed при необходимости. Важно, чтобы seed был одинаковым для всех $\kappa$ в рамках одного случая $r$.}

\subsubsection{Оценка множителя по сетке}

Для каждого пола $g$ рассматривается фиксированная сетка кандидатов:
$$
\mathcal{K} = \{0.50,\ 0.55,\ 0.60,\ \dots,\ 3.00\}
$$
с шагом $0.05$.\footnote{MVP: сетка $\mathcal{K}$ является частью конфигурации модели. Шаг $0.05$ обеспечивает достаточную точность калибровки при разумных вычислительных затратах.}

Для каждого $\kappa \in \mathcal{K}$ и каждого $r \in \mathcal{I}_g^{\text{LOY}}$ пересчитываются Монте-Карло траектории с тем же $\kappa$:
$$
Z_r^{(b)}(\kappa)
=
\hat m_r + \kappa\, s_{\text{pred},r}\, \xi_r^{(b)},
$$
$$
Y_r^{(b)}(\kappa)
=
\ln \hat R^{\text{use}}_r
+
Z_r^{(b)}(\kappa)
+
\delta_r^{(b)},
\qquad
b=1,\dots,N_r,
$$
где $N_r$ — финальный объём моделирования для случая $r$ (определённый адаптивной процедурой при $\kappa=1$ в LOY-режиме).

По этим выборкам вычисляются квантили $\widehat q_{0.05,r}(\kappa)$ и $\widehat q_{0.95,r}(\kappa)$ по описанному ранее протоколу type 7, после чего вычисляется эмпирическое покрытие $\widehat{\text{cov}}_g(\kappa)$.

Если число LOY-случаев удовлетворяет условию
$$
|\mathcal{I}_g^{\text{LOY}}| \ge N_{\text{cov,min}},
\qquad
N_{\text{cov,min}} = 200,
$$
множитель $\kappa_g$ определяется как
$$
\kappa_g
=
\min\Bigl\{
\kappa \in \mathcal{K}:
\bigl|\widehat{\text{cov}}_g(\kappa) - 0.90\bigr|
=
\min_{\kappa' \in \mathcal{K}}
\bigl|\widehat{\text{cov}}_g(\kappa') - 0.90\bigr|
\Bigr\}.
$$

При равенстве отклонений выбирается наименьшее значение $\kappa$ (консервативная стратегия: более узкие интервалы).

Если $|\mathcal{I}_g^{\text{LOY}}| < N_{\text{cov,min}}$, калибровка не проводится из-за недостаточного объёма данных, и полагается
$$
\kappa_g = 1.
$$

\footnote{MVP: порог $N_{\text{cov,min}}=200$ обеспечивает достаточную статистическую мощность для оценки покрытия $0.90$ с разумной точностью (стандартная ошибка $\approx 0.02$). При меньших объёмах калибровка ненадёжна.}

\subsubsection{Использование в рабочем режиме (production)}

В рабочем режиме (production) для пола $g$ используется одно фиксированное значение $\kappa_g$, полученное по описанной процедуре (или $\kappa_g=1$, если калибровка невозможна). Значение $\kappa_g$ хранится в конфигурации модели отдельно для мужчин и женщин и не переоценивается при каждом прогнозе.

Для любой новой цели $(c^\ast,g,j^\ast,a_{\text{new}})$ схема Монте-Карло имеет вид:
$$
Z_{\text{new}}^{(b)}
=
\hat m_\ast + \kappa_g s_{\text{pred}}\,\xi^{(b)},
$$
$$
Y_{\text{new}}^{(b)}
=
\ln \hat R^{\text{use}}
+
Z_{\text{new}}^{(b)}
+
\delta^{(b)},
$$
где
$$
\xi^{(b)} \sim t_{\nu_g}, 
\qquad
\delta^{(b)} \sim N\bigl(0,\tau^{2,\text{use}}\bigr),
$$
а все остальные элементы численного протокола (инициализация генератора, объём моделирования, квантильный алгоритм и критерии недоступности) совпадают с описанными ранее и не зависят от процедуры калибровки.

\subsubsection{Граничные случаи}

Если для пола $g$ не удалось выполнить калибровку (недостаточно LOY-случаев или все LOY-прогнозы недоступны), используется $\kappa_g=1$. Это соответствует номинальному покрытию на основе модели без эмпирической корректировки.

Если калибровка показывает, что оптимальное $\kappa_g$ находится на границе сетки $\mathcal{K}$ (например, $\kappa_g=0.50$ или $\kappa_g=3.00$), это сигнализирует о потенциальных проблемах с моделью (систематическое занижение/завышение неопределённости). Требуется диагностика параметров модели.\footnote{MVP: граничные значения $\kappa_g$ должны логироваться как предупреждения. В типичных случаях $\kappa_g\in[0.8, 1.3]$.}


\subsection{Условия доступности прогноза}

Во всех режимах прогноз строится только при выполнении структурных и численных условий. Проверки выполняются на данных, соответствующих выбранному режиму. Если нарушено хотя бы одно из условий ниже, прогноз для конфигурации $(c^\ast,g,j^\ast,a_{\text{new}})$ признаётся недоступным.

В режиме LOY для цели $(c^\ast,g,j^\ast,a_{\text{new}})$ используется множество годов
$$
J^{(-j^\ast)} = J \setminus \{j^\ast\}.
$$

В режиме production используется множество годов $J'$, которое применено при построении выбранного эталона $\hat R^{\text{use}}$ для цели $(c^\ast,g,j^\ast)$.
В зависимости от статуса года $j^\ast$ это либо $J'=J^{(-j^\ast)}$ (если $j^\ast \in J$), либо $J'=J$ (если $j^\ast \notin J$).

\subsubsection{Структурные условия}

\paragraph{Доступность эталона нормировки.}
Пусть $J'$ --- множество годов, использованное при построении выбранного эталона $\hat R^{\text{use}}$ для цели $(c^\ast,g,j^\ast)$ в текущем режиме.

Обозначим через $n_{c^\ast,g}(J')$ число доступных финишей пары $(c^\ast,g)$ в годах из $J'$ после очистки данных (статус OK, заданное время финиша). Требуется
$$
n_{c^\ast,g}(J') \ge n_{\min},
$$
где $n_{\min}$ --- фиксированный порог.\footnote{MVP: в текущей конфигурации $n_{\min}$ выбран так, что условие $n_{c,g}(J')\ge n_{\min}$ автоматически обеспечивает достаточный размер top-набора $|S_{c,g}(J')|\ge m_{\min}$ при $p_{\text{top}}=0.05$. Конкретно, $n_{\min}=\lceil m_{\min}/p_{\text{top}}\rceil$.}

Если условие не выполнено, эталон $\hat R^{\text{use}}$ и связанный с ним прогноз считаются недоступными.

\paragraph{Достаточный размер top-набора для дисперсии эталона.}
Обозначим через $S_{c^\ast,g}(J')$ top-набор, построенный по протоколу top-отбора: берутся первые
$$
m_{\text{top}}=\bigl\lceil p_{\text{top}}\cdot n_{c^\ast,g}(J')\bigr\rceil
$$
значений после сортировки по возрастанию времени, где $p_{\text{top}}=0.05$.
Тогда
$$
|S_{c^\ast,g}(J')| = m_{\text{top}}.
$$

Для оценки $\tau^{2,\text{use}}$ используется ровно тот же top-набор $S_{c^\ast,g}(J')$, который применён при вычислении выбранного эталона
$$
\hat R^{\text{use}}=\operatorname{med}\bigl(S_{c^\ast,g}(J')\bigr).
$$
Требуется
$$
|S_{c^\ast,g}(J')| \ge m_{\min},
$$
где $m_{\min}$ --- фиксированный порог.\footnote{MVP: в текущей конфигурации $m_{\min}=10$. Это минимальный размер выборки для устойчивой оценки медианы и бутстрэп-дисперсии.}

Если это условие не выполнено, $\tau^{2,\text{use}}$ считается недоступной, и прогноз не строится.

\paragraph{Проверки в режиме LOY.}
В режиме LOY все условия доступности, связанные с эталоном и top-набором, проверяются по множеству годов $J^{(-j^\ast)}=J\setminus\{j^\ast\}$.
Для пары $(c,g)$ и фиксированного $j^\ast$ вводится обозначение
$$
n_{c,g,-j^\ast} = n_{c,g}(J^{(-j^\ast)}).
$$

\paragraph{Достаточное число внутренних узлов сплайна.}
После построения и детерминированного слияния узлов возрастной модели для пола $g$ итоговое число внутренних узлов $K^{\text{(inner)}}_g$ (без учёта граничных) должно удовлетворять
$$
K^{\text{(inner)}}_g \ge K^{\text{(inner)}}_{\min},
\qquad
K^{\text{(inner)}}_{\min} = 3.
$$
Если после слияний это условие нарушено, узловая конфигурация считается вырожденной, возрастная модель для пола $g$ в данном режиме недоступна, и прогноз невозможен.

\paragraph{Возраст в пределах узлов.}
Прогноз возможен только для возрастов $a_{\text{new}}$ внутри диапазона узлов возрастной модели для пола $g$ в текущем режиме:
$$
t_{g,0} \le a_{\text{new}} \le t_{g,m_g},
$$
где $t_{g,0}$ и $t_{g,m_g}$ --- минимальный и максимальный узлы после слияния.

Экстраполяция за пределы диапазона узлов не допускается: если $a_{\text{new}} < t_{g,0}$ или $a_{\text{new}} > t_{g,m_g}$, прогноз объявляется недоступным.

\subsubsection{Численные условия}

\paragraph{Устойчивость QR-разложения.}
Пусть
$$
R_g = R^{\text{qr}}_g(\hat\lambda_g)
$$
--- квадратная верхнетреугольная матрица размера $p_g\times p_g$, полученная при QR-разложении расширенной матрицы $\widetilde{W}_g(\hat\lambda_g)$ при оптимальном параметре сглаживания.

Вводится порог
$$
\varepsilon_{\mathrm{qr}} = 10^{-10}.
$$
Требуется, чтобы для всех диагональных элементов выполнялось
$$
|R_{g,kk}|
\ge
\varepsilon_{\mathrm{qr}}
\cdot
\max\Bigl(1,\ \max_\ell |R_{g,\ell\ell}|\Bigr),
\qquad
k=1,\dots,p_g.
$$
Если существует индекс $k$, для которого неравенство нарушено, QR-разложение считается численно неустойчивым, и прогноз объявляется недоступным.

\footnote{MVP: порог $\varepsilon_{\mathrm{qr}}$ фиксирован и одинаков для всех запусков. При необходимости он уточняется по результатам тестов на реальных данных, но не подстраивается под конкретную цель.}

\paragraph{Положительность прогностической дисперсии.}
Прогностическая дисперсия на шкале $Z$ задаётся выражением
$$
s_{\text{pred}}^2 = \hat\sigma_g^2 \bigl(1 + c_\ast^\top w\bigr),
$$
где вектор $w\in\mathbb{R}^{p_g}$ определяется через последовательное решение треугольных систем
$$
R_g^\top u = c_\ast,
\qquad
R_g w = u
$$
с матрицей $R_g$.

Теоретически при корректных матрицах величина $c_\ast^\top w \ge 0$, поэтому $1 + c_\ast^\top w \ge 1$. На практике проверяется диагностическое условие
$$
1 + c_\ast^\top w > 0.
$$
Если численно получается $1 + c_\ast^\top w \le 0$, это трактуется как сбой вычислений (потеря устойчивости или вырождение), и прогноз объявляется недоступным.

\paragraph{Достаточное число степеней свободы.}
Число степеней свободы возрастной модели для пола $g$ при оптимальном значении параметра сглаживания $\hat\lambda_g$ задаётся формулой
$$
\nu_g = n_g - \mathrm{edf}_g(\hat\lambda_g),
$$
где $n_g$ --- число обучающих наблюдений пола $g$ в текущем режиме. Требуется
$$
\nu_g > \nu_{\min},
\qquad
\nu_{\min} = 3.
$$
Если $\nu_g \le \nu_{\min}$, возрастная модель считается переобученной, и прогноз объявляется недоступным.

\footnote{MVP: порог $\nu_{\min}=3$ обеспечивает минимальную надёжность распределения Стьюдента $t_{\nu_g}$. При $\nu_g\le 3$ хвосты распределения слишком тяжёлые, и прогнозные интервалы становятся ненадёжными.}

\paragraph{Сходимость моделирования методом Монте-Карlo.}
Адаптивный протокол метода Монте-Карло использует последовательность объёмов
$$
N_{\min},\ 2N_{\min},\ 4N_{\min},\ \dots,\ N_{\max},
$$
где $N_{\min}=25\,000$ и $N_{\max}=400\,000$.

На каждом шаге с объёмами $N$ и $N'=\min(2N,N_{\max})$ вычисляются оценки квантилей по шкале $Y=\ln T$ для контрольных уровней
$$
\mathcal{P}_{\text{check}}=\{0.05,0.50,0.95\},
$$
обозначаемые через $\widehat q_p^{(N)}(Y)$ и $\widehat q_p^{(N')}(Y)$.

Наблюдаемое отклонение определяется как
$$
\Delta_Y^{\text{obs}} =
\max_{p \in \mathcal{P}_{\text{check}}}
\bigl|\widehat q_p^{(N')}(Y) - \widehat q_p^{(N)}(Y)\bigr|.
$$
Сходимость считается достигнутой, если
$$
\Delta_Y^{\text{obs}} \le \Delta_Y,
\qquad
\Delta_Y = 0.002.
$$
Если до момента достижения $N'=N_{\max}$ ни разу не выполнено условие сходимости, прогноз для данной цели признаётся недоступным из-за недостаточной сходимости квантилей.

\footnote{MVP: недостаточная сходимость при $N_{\max}=400\,000$ указывает на проблемы с параметрами модели: слишком малое $\nu_g$, слишком большое $\tau^{2,\text{use}}$, или экстремальные значения $\hat m_\ast$, $s_{\text{pred}}$. Требуется диагностика.}

\subsubsection{Интерпретация статуса «прогноз недоступен»}

Статус «прогноз недоступен» означает, что для выбранной конфигурации $(c^\ast,g,j^\ast,a_{\text{new}})$ модель не может обеспечить контролируемое качество оценки при заданных структурных и численных ограничениях.

Этот статус не рассматривается как ошибка модели. Он отражает требования к корректности эталонов, достаточности данных для возрастной модели, устойчивости численных процедур и надёжности Монте-Карlo процедуры.

В реализации каждый случай недоступности должен логироваться с указанием конкретной причины (какое условие нарушено) для диагностики и мониторинга качества модели.


\subsection{Пошаговая реализация}

Этот раздел фиксирует практическую последовательность шагов, необходимую для построения прогноза времени финиша с поправкой по возрасту. Описание не содержит математических выводов и служит операционным регламентом.

Все действия выполняются отдельно для каждого пола. Все проверки структурных и численных условий выполняются в том мире данных, который соответствует выбранному режиму: в режиме LOY (обучение по годам) используются годы $J^{(-j^\ast)}$ для каждой цели $j^\ast$, в режиме production используется множество годов $J'$, на котором построен выбранный эталон $\hat R^{\text{use}}$ для данной цели $(c^\ast,g,j^\ast)$.

\subsubsection{Обработка и подготовка данных}

\begin{enumerate}
\item \textbf{Считать исходные данные стартов.}
Используются только записи с измеренным временем финиша и корректно заданными атрибутами трассы, пола, года и возраста. Дальнейшие шаги выполняются по данным после базовой очистки (статус OK, время финиша задано, ключевые поля не пустые).

\item \textbf{Уникализировать наблюдения.}
Для каждой тройки ``участник, трасса, год'' оставить одну запись: выбрать наблюдение с минимальным временем финиша $T$, а при равенстве $T$ выбрать запись с минимальным идентификатором старта.

\item \textbf{Задать множество годов для каждого режима.}
\begin{itemize}
\item \textit{LOY.} Для каждой цели с годом $j^\ast$ используется $J^{(-j^\ast)}=J\setminus\{j^\ast\}$.
\item \textit{production.} Для цели $(c^\ast,g,j^\ast)$ используется множество годов $J'$, определяемое протоколом эталона: если $j^\ast\in J$, то $J'=J^{(-j^\ast)}$, если $j^\ast\notin J$, то $J'=J$.
\end{itemize}
Все последующие операции (включая проверки доступности, построение эталонов и обучение возрастной модели) выполняются по данным соответствующего режима.

\item \textbf{Построить и сохранить эталоны нормировки.}
Для каждой пары ``трасса, пол'' и для каждого допустимого $J'$ построить:
\begin{itemize}
\item top-набор $S_{c,g}(J')$ по протоколу top-отбора (по фиксированному $p_{\text{top}}$),
\item эталон $\hat R^{\text{use}}_{c,g}(J')=\operatorname{med}(S_{c,g}(J'))$,
\item процедурную оценку дисперсии ошибки эталона $\tau^{2,\text{use}}_{c,g}(J')$, вычисленную бутстрэпом по фиксированному набору $S_{c,g}(J')$ (top-отбор внутри бутстрэп-реплик не повторяется).
\end{itemize}
Пара $(\hat R^{\text{use}},\tau^{2,\text{use}})$ для каждой цели фиксируется согласованно: на одном и том же $J'$ и на одном и том же top-наборе $S$.

\item \textbf{Проверить базовую доступность эталона и дисперсии эталона.}
Для каждого $(c,g,J')$ проверить структурные условия из раздела ``Условия доступности прогноза'':
\begin{itemize}
\item $n_{c,g}(J') \ge n_{\min}$ (доступность эталона),
\item $|S_{c,g}(J')| \ge m_{\min}$ (доступность $\tau^{2,\text{use}}$).
\end{itemize}
Если условие нарушено, соответствующие цели $(c,g,j)$, которые опираются на этот $J'$, объявляются недоступными по эталону (и не участвуют ни в обучении, ни в прогнозе).

\item \textbf{Нормировать наблюдения.}
Для каждого наблюдения $r$ вычислить нормированное значение на шкале $Z$:
$$
z_r = \ln T_r - \ln \hat R^{\text{use}}_{c(r),g(r)}(j(r)),
$$

где используется именно тот эталон $\hat R^{\text{use}}$, который соответствует трассе, полу и году наблюдения и построен по протоколу эталона в данном режиме.

\item \textbf{Сформировать рабочие таблицы для прогнозов.}
Подготовить для каждого режима и пола:
\begin{itemize}
\item таблицу соответствий ``цель $\to$ эталон'' (для каждой цели хранить используемое $J'$, $\hat R^{\text{use}}$, $\tau^{2,\text{use}}$, а также параметры top-отбора),
\item таблицу обучающих наблюдений на шкале $Z$ с возрастом и техническими полями, необходимыми для построения базиса и дальнейшей оценки модели.
\end{itemize}
\end{enumerate}

\subsubsection{Обучение возрастной модели по полу}

\begin{enumerate}
\item \textbf{Сформировать узлы возрастного сплайна.}
На основе обучающих наблюдений данного пола после всех фильтраций построить узлы возрастного сплайна по детерминированной схеме. Затем выполнить детерминированное слияние близких узлов по заданным правилам.
Если итоговое число внутренних узлов $K^{\text{(inner)}}_g$ меньше минимально допустимого порога, возрастная модель для пола $g$ объявляется недоступной, и дальнейшие шаги для этого пола не выполняются.

\item \textbf{Построить базис возрастной части.}
Сформировать матрицу объясняющих переменных для всех обучающих наблюдений данного пола на шкале $Z$:
включить константу, нормированный возраст и значения центрированных базисных функций.

\item \textbf{Очистить нормированные значения.}
К нормированным значениям $z_r$ применить процедуру устойчивой очистки (MAD-винзоризацию), определённую в данной главе. Очистка выполняется по обучающей выборке данного пола до начала оценки модели в режиме REML.

\item \textbf{Оценить параметры модели в режиме REML.}
\begin{itemize}
\item На основе эталонов трасс и их дисперсий вычислить усреднённую дисперсию ошибок эталонов по трассам для данного пола.
\item Выполнить оценку параметров смешанной модели в режиме REML для пола $g$.
\item Найти оптимальный параметр сглаживания $\hat\lambda_g$.
\item Сохранить коэффициенты модели, матрицу $R_g(\hat\lambda_g)$, оценку $\hat\sigma_g^2$ и число степеней свободы $\nu_g$, а также служебные объекты, необходимые для прогноза.
\end{itemize}

\item \textbf{Проверить минимальные требования к возрастной модели.}
Проверить, что:
\begin{itemize}
\item $K^{\text{(inner)}}_g \ge K^{\text{(inner)}}_{\min}$,
\item $\nu_g > \nu_{\min}$,
\item выполнены критерии устойчивости QR-разложения для матрицы $R_g(\hat\lambda_g)$ по заданному порогу.
\end{itemize}
Если хотя бы одно требование нарушено, возрастная модель для данного пола считается недоступной.
\end{enumerate}

\subsubsection{Прогноз для заданной цели}

Для каждой цели $(c^\ast,g,j^\ast,a_{\text{new}})$ выполняется следующая последовательность действий.

\begin{enumerate}
\item \textbf{Проверка доступности прогноза.}
\begin{itemize}
\item Определить множество годов $J'$ для цели $(c^\ast,g,j^\ast)$ в выбранном режиме и проверить доступность эталона на $J'$.
\item Проверить, что доступна согласованная пара $(\hat R^{\text{use}},\tau^{2,\text{use}})$, построенная на одном и том же $J'$ и на одном и том же top-наборе $S$, и что выполнено требование $|S|\ge m_{\min}$.
\item Проверить, что возрастная модель для пола $g$ доступна (выполнены минимальные требования по узлам, $\nu_g$ и устойчивости QR).
\item Проверить корректность возраста $a_{\text{new}}$: он должен находиться в диапазоне узлов возрастной модели для пола $g$ в текущем режиме. Экстраполяция по возрасту не выполняется.
\item Проверить диагностическое условие прогностической дисперсии $1 + c_\ast^\top w > 0$ при вычислении $s_{\text{pred}}^2$.
\end{itemize}
Если хотя бы одно условие нарушено, прогноз получает статус ``прогноз недоступен'', и дальнейшие шаги не выполняются.

\item \textbf{Сформировать вектор признаков цели $c_\ast$}
Сформировать вектор признаков цели $c_\ast$ (константа, нормированный возраст, значения центрированных базисных функций). Затем вычислить
$$
\hat m_\ast = c_\ast^\top \hat\theta_{g}.
$$
Одновременно вычислить прогностический масштаб $s_{\text{pred}}$ и число степеней свободы $\nu_g$, используемые в порождающей схеме.

\item \textbf{Выбрать множитель $\kappa_g$.}
В режиме LOY используется $\kappa_g=1$.
В режиме production используется фиксированное значение $\kappa_g$ для пола $g$, полученное по процедуре калибровки покрытия и сохранённое в конфигурации.\footnote{MVP: допускается временно положить $\kappa_g=1$ в обоих режимах.}

\item \textbf{Зафиксировать $\ln \hat R^{\text{use}}_{c^\ast,g}(j^\ast)$ как сдвиг при переходе от шкалы $Z^\ast$ к шкале $Y=\ln T$.}
Зафиксировать $\ln \hat R^{\text{use}}_{c^\ast,g}(j^\ast)$ как сдвиг при переходе от шкалы $Z^\ast$ к шкале $Y=\ln T$. Учёт дисперсии ошибки эталона выполняется только через добавку $\delta$ в методе Монте-Карло. Аналитические поправки к дисперсии не используются.

\item \textbf{Получить выборку методом Монте-Карло.}
\begin{itemize}
\item Инициализировать генератор случайных чисел детерминированным seed по протоколу из раздела ``Численный расчёт прогноза методом Монте-Карло''. Для данной цели используется одно и то же seed как в режиме LOY, так и в режиме production.
\item Запустить адаптивную процедуру Монте-Карlo, начиная с $N_{\min}$ и используя вложенную последовательность объёмов до $N_{\max}$.
\item На каждом шаге сгенерировать
$$
Z_{\text{new}}^{(b)}=\hat m_\ast+\kappa_g s_{\text{pred}}\xi^{(b)},\qquad \xi^{(b)}\sim t_{\nu_g},
$$
$$
Y_{\text{new}}^{(b)}=\ln \hat R^{\text{use}}_{c^\ast,g}(j^\ast)+Z_{\text{new}}^{(b)}+\delta^{(b)},\qquad \delta^{(b)}\sim N\bigl(0,\tau^{2,\text{use}}\bigr),
$$
и проверить критерий сходимости квантилей по шкале $Y$:
$$
\Delta_Y^{\text{obs}}=\max_{p\in\mathcal{P}_{\text{check}}}\bigl|\widehat q_p^{(N')}(Y)-\widehat q_p^{(N)}(Y)\bigr|\le \Delta_Y.
$$
\item Если сходимость не достигнута при $N_{\max}$, прогноз объявляется недоступным.
\end{itemize}

\item \textbf{Вычислить отчётные величины.}
Если адаптивная процедура сошлась при $N_{\text{final}}$, по финальной выборке $\{Y_{\text{new}}^{(b)}\}_{b=1}^{N_{\text{final}}}$ вычислить отчётные квантили на шкале $Y$.
Квантили на шкале времени $T$ получить только преобразованием
$$
q_p(T)=\exp\bigl(q_p(Y)\bigr).
$$
Прямые квантили по выборке $\{T_{\text{new}}^{(b)}\}$ не используются как отчётные.
\end{enumerate}

\subsubsection*{Структура реализации}

\begin{itemize}
\item Подсистема подготовки данных: чтение исходных данных, уникализация наблюдений, выбор мира данных (LOY или production), построение и проверка эталонов,вычисление $z_r$ и подготовка таблиц целей.
\item Подсистема обучения возрастной модели: построение узлов, формирование базиса, MAD-винсоризация, REML-оценка, сохранение объектов для прогноза и проверка минимальных требований.
\item Подсистема прогноза: проверка условий доступности, вычисление $\hat m_\ast$ и $s_{\text{pred}}$, выбор $\kappa_g$, адаптивное Монте-Карlo моделирование и расчёт отчётных квантилей на шкалах $Y$ и $T$.
\end{itemize}

\subsection{Резюме главы и связь с дальнейшими уровнями}

\subsubsection{Основные результаты и ограничения}

В этой главе к трассовому уровню модели добавлена явная возрастная поправка на нормированной шкале $Z$. Логарифм времени финиша $Y=\ln T$ представляется как сумма логарифма эталона, возрастной компоненты и шума. Эталон $\hat R^{\text{use}}_{c,g}(j)$ описывает типичное время финиша для цели $(c,g,j)$, а возрастная модель понижает или повышает нормированное значение относительно этого эталона.

Возрастная компонента задаётся сглаживающей функцией по возрасту на шкале $Z$, общей для всех трасс внутри пола. Эта функция реализуется в виде сплайна; узлы сплайна строятся детерминированным алгоритмом по распределению возрастов в обучающей выборке данного пола в выбранном режиме (LOY или production). Правило построения узлов фиксировано, но сами узлы зависят от данных, то есть не являются глобальными константами.

Для каждого пола $g$ в выбранном режиме получено:
\begin{itemize}
\item единая возрастная функция на нормированной шкале
$Z=\ln T-\ln \hat R^{\text{use}}_{c,g}(j)$;
\item точечный прогноз на нормированной шкале $\hat m_\ast$ и базовый прогностический масштаб $s_{\text{pred}}$ для любой цели $(c^\ast,g,j^\ast,a_{\text{new}})$, удовлетворяющей условиям доступности прогноза;
\item рабочее прогностическое распределение шума на шкале $Z$, в котором в порождающей схеме используется $\xi\sim t_{\nu_g}$ (распределение Стьюдента с $\nu_g$ степенями свободы) и масштаб $s_{\text{pred}}$.
\end{itemize}

Рабочий масштаб $\hat\sigma_g^2$ для пола $g$ получается из REML-оценки дисперсии на шкале $Z$ с методической поправкой на средний вклад ошибки эталона: из REML-оценки вычитается средняя дисперсия ошибки эталона по трассам $\overline{\tau^2}_g$. На основе $\hat\sigma_g^2$ и структуры возрастной модели строится базовый прогностический масштаб $s_{\text{pred}}$ на шкале $Z$. Компонента $\tau^{2,\text{use}}$ для конкретной цели остаётся отдельной: она учитывается на шкале $Y$ через нормальную добавку $\delta\sim N(0,\tau^{2,\text{use}})$ и не включается в $s_{\text{pred}}$.

В базовой конструкции разложение устроено так:
\begin{itemize}
\item индивидуальная компонента шума на шкале $Z$ внутри пола описывается единым рабочим масштабом $\hat\sigma_g^2$ и далее $s_{\text{pred}}$; при фиксированном режиме предполагается условная однородность дисперсии внутри пола после методической поправки на $\overline{\tau^2}_g$;
\item итоговая неопределённость на шкале $Y$ различается между целями за счёт добавляемой компоненты ошибки эталона $\tau^{2,\text{use}}$, которая входит в порождающую схему через $\delta\sim N(0,\tau^{2,\text{use}})$.
\end{itemize}

Шум на шкале $Z$ в прогнозе моделируется рабочим прогностическим распределением на основе распределения Стьюдента: в порождающей схеме используется $\xi\sim t_{\nu_g}$ и масштаб $s_{\text{pred}}$ или $\kappa_g s_{\text{pred}}$ в зависимости от режима. Это калиброванная инженерная модель шума, а не строгий вывод из классической линейной теории, поскольку MAD-винзоризация, вычитание средней компоненты $\overline{\tau^2}_g$ и последующая калибровка множителя $\kappa_g$ вводятся как рабочие элементы и нарушают прямую применимость стандартных выводов.

Поэтому распределение $Z_{\text{new}}$ и, тем более, $Y_{\text{new}}$ рассматривается как рабочая аппроксимация, реализуемая через порождающую схему, а не как аналитическое распределение $t_\nu$.

Базовый прогностический масштаб $s_{\text{pred}}$ определяется возрастной моделью и оценкой дисперсии для пола $g$ в фиксированном режиме (LOY или production). Дальнейшая калибровка разброса проводится через множитель $\kappa$:
\begin{itemize}
\item в режиме LOY модель для нормированного прогноза применяется при $\kappa=1$ и используется для валидации;
\item при калибровке по покрытию в режиме LOY перебираются значения $\kappa$ на сетке и оценивается эмпирическое покрытие прогнозных интервалов по шкале $Y$, полученных методом Монте-Карло;
\item в режиме production используется фиксированное значение $\kappa_g$, полученное из калибровки по полу $g$, и масштаб шума на шкале $Z$ задаётся как $\kappa_g s_{\text{pred}}$.
\end{itemize}
Таким образом, возрастная модель и базовый масштаб $s_{\text{pred}}$ не зависят от $\kappa_g$, а множитель $\kappa_g$ только масштабирует разброс на этапе генерации выборки Монте-Карло.

Прогнозные распределения на шкалах $Y$ и $T$ строятся только методом Монте-Карло. Для каждой доступной цели $(c^\ast,g,j^\ast,a_{\text{new}})$ используется нормативный протокол моделирования с детерминированным начальным значением генератора, фиксированными уровнями квантилей и адаптивным выбором объёма выборки. Аналитические $t$-интервалы на шкале $Z$ в отчётных прогнозах не используются: все отчётные интервалы выводятся только из выборки, сгенерированной по порождающей схеме метода Монте-Карло. Упоминания распределения Стьюдента относятся к рабочему виду порождающей схемы шума, а не к отдельному аналитическому механизму построения интервалов.

Пара $(\hat R^{\text{use}}_{c,g}(j),\tau^{2,\text{use}})$ всегда рассматривается как единый объект: эталон и дисперсия ошибки эталона строятся на одном и том же множестве годов $J'$ и одном и том же top-наборе стартов, а затем совместно используются при переходе от $Z$ к $Y$. Условия, при которых прогноз признаётся недоступным, совпадают с формальным списком условий доступности прогноза, выделенным в отдельном разделе главы. В резюме можно выделить основные типы ограничений:
\begin{itemize}
\item достаточный объём данных для построения эталонов и процедурных оценок дисперсий (по порогам $n_{\min}$, $m_{\min}$ и фиксированному $p_{\text{top}}$, а также другим численным порогам из раздела условий доступности);
\item минимальное число внутренних узлов возрастного сплайна;
\item минимальный порог для степеней свободы $\nu_g$ (в выбранном режиме);
\item устойчивость QR-разложения (по порогу для диагональных элементов матрицы $R_g$);
\item диагностическое условие $1+c_\ast^\top w>0$ для прогностической дисперсии;
\item достижение требуемой точности по $\Delta_Y$ в адаптивной процедуре метода Монте-Карло;
\item принадлежность возраста $a_{\text{new}}$ диапазону узлов возрастной модели.
\end{itemize}
Формальные формулировки этих критериев и точные численные пороги заданы в разделе условий доступности; здесь перечисляются только их типы.

Основные ограничения построенной конструкции можно суммировать так:
\begin{itemize}
\item индивидуальная компонента шума на $Z$ внутри пола описывается одной условно однородной дисперсией (после методической поправки на $\overline{\tau^2}_g$), без явного моделирования гетероскедастичности по возрасту, трассам или годам;
\item возрастная функция описывает только средний возрастной профиль и не включает индивидуальные поправки конкретных участников;
\item возможные корреляции между ошибкой эталона и индивидуальным шумом не моделируются и заменяются допущением независимости;
\item в каждом полу используется одномерная схема шума, без явной многомерной структуры зависимостей между стартами или трассами.
\end{itemize}

\subsubsection{Интеграция в общую архитектуру прогнозов}

Возрастной уровень интегрируется в общую архитектуру прогнозов как слой поверх трассовых эталонов. При выполнении условий доступности прогноза для цели $(c^\ast,g,j^\ast,a_{\text{new}})$ используется следующая последовательность:
\begin{enumerate}
\item выбирается эталон $\hat R^{\text{use}}_{c^\ast,g}(j^\ast)$ и соответствующая дисперсия ошибки $\tau^{2,\text{use}}$, построенные на согласованном множестве годов $J'$ и top-наборе стартов;
\item по возрастной модели для пола $g$ и возраста $a_{\text{new}}$ вычисляются точечный прогноз $\hat m_\ast$ и базовый прогностический масштаб $s_{\text{pred}}$ на шкале $Z$;
\item формируется масштаб шума на $Z$: в режиме LOY при валидации используется масштаб $s_{\text{pred}}$, в режиме production используется калиброванный множитель $\kappa_g$ и масштаб $\kappa_g s_{\text{pred}}$;
\item на основе $(\hat m_\ast, s_{\text{pred}}, \kappa_g, \nu_g, \hat R^{\text{use}}_{c^\ast,g}(j^\ast), \tau^{2,\text{use}})$ по протоколу моделирования методом Монте-Карlo строится выборка значений $Y_{\text{new}}$ и отчётные квантили на шкалах $Y$ и $T$.
\end{enumerate}

В рамках данной главы протокол построения эталонов, возрастная модель, рабочее прогностическое распределение на основе распределения Стьюдента и процедура калибровки множителя $\kappa_g$ считаются фиксированными элементами архитектуры. Дальнейшее развитие модели предполагается за счёт добавления дополнительных уровней поверх уже нормированной и скорректированной по возрасту шкалы $Z$. Возможные направления развития включают:
\begin{itemize}
\item годовые поправки, описывающие систематические сдвиги относительно возрастной кривой в разные годы;
\item индивидуальные поправки, отражающие устойчивые отличия конкретных участников от среднего возрастного профиля;
\item дополнительные компоненты шума и структуры зависимостей между стартами или трассами, заданные поверх базовой одномерной модели шума по полу.
\end{itemize}
Эти направления находятся вне текущей модели и требуют отдельной постановки. При их разработке предполагается сохранять согласованность с существующими критериями доступности прогноза и базовой конструкцией эталонов, возрастной модели и протокола моделирования методом Монте-Карло; при необходимости изменения этих элементов требуется отдельное явное описание.

\subsubsection*{Что сознательно оставлено вне модели}

В этой главе фиксируется базовый уровень архитектуры, который сочетает:
\begin{itemize}
\item трассовые эталоны и процедурные оценки дисперсий ошибки эталона;
\item возрастную модель по полу на нормированной шкале $Z$;
\item рабочее прогностическое распределение с условно однородной индивидуальной дисперсией на $Z$ и отдельной компонентой ошибки эталона на шкале $Y$;
\item протокол моделирования методом Монте-Карlo для расчёта прогнозов и отчётных квантилей.
\end{itemize}

Сознательно оставлены вне рамок текущей модели:
\begin{itemize}
\item явное моделирование гетероскедастичности индивидуального шума по возрасту, трассам или годам;
\item совместное построение годовых поправок и возрастной компоненты, а также отдельные годовые поправки поверх уже нормированной возрастной модели;
\item индивидуальные поправки по участникам, моделирующие их устойчивые отклонения от среднего возрастного профиля;
\item многомерные модели зависимостей на основе функций связи, в которых сначала задаются одномерные распределения компонент, а затем их совместное распределение строится через специальную многомерную функцию распределения с равномерными одномерными распределениями каждой компоненты.
\end{itemize}

Эти направления рассматриваются как возможные расширения архитектуры прогнозов и требуют отдельной постановки.
